{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook serves as an exploration of orbital debris modeling and an introduction to ODAP (Orbital Debris Analysis with Python). While ODAP is currently being refined and converted into a standalone module, you will be able to explore how the module functions and can be utilized in research throughout this notebook.\n",
    "\n",
    "Initially, this project started from a personal curiosity about how orbital debris works, but later was the basis for a senior thesis written while attending the Harriet L. Wilkes Honors College. The purpose is to develop a modern open-source python implementation of the NASA Standard Breakup Model that others can use to research orbital debris.\n",
    "\n",
    "Since this project is on going, please note that some functionality may not be working as expected as I continue to go through the process of optimizing and validating the implementations of the various components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "### 0. [Packages](#packages)\n",
    "Covers the initial setup to enable the notebook to function correctly\n",
    "### 1. [Data Source](#data-source)\n",
    "Loading real world data from Two Line Elements to use as the foundation for the rest of the simulations\n",
    "### 2. [Fragmentation Event Modeling](#fragmentation)\n",
    "### 3. [Cloud Formation and Propagation](#cloud)\n",
    "### 4. [Analysis](#second-bullet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"packages\"></a>\n",
    "<h1>0. Packages</h1>\n",
    "\n",
    "For the purposes of this notebook I will be using a variety of other common modules such as NuMpy, pandas, and Plotly. As such, the below cell will import all necessary modules, as well as import various components from ODAP that will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-27T17:21:14.872913Z",
     "start_time": "2021-10-27T17:21:02.278959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System lib.\n",
    "import sys\n",
    "import os\n",
    "from itertools import product, combinations\n",
    "from enum import IntEnum\n",
    "from importlib import reload\n",
    "\n",
    "# 3rd party lib.\n",
    "import numpy as np\n",
    "import re\n",
    "import skyfield.sgp4lib as spg4\n",
    "import matplotlib \n",
    "import PyQt5\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "from skyfield.api import wgs84\n",
    "from enum import IntEnum    \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from scipy import integrate\n",
    "from numba import njit, prange\n",
    "\n",
    "# User defined lib.\n",
    "if not os.path.join(sys.path[0], '..') in sys.path:\n",
    "    sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "import odap.generate_debris as gd\n",
    "import odap.CoordTransforms as ct\n",
    "import odap.visualize_deb as vis\n",
    "import data.planetary_data\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib qt5\n",
    "debris_category = IntEnum('Category', 'rb sc soc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To streamline the process of visualizations, I make frequently save various plots to a folder. Additionally, I have critical plots uploaded to Plotlys cloud service for easy sharing. This cell handles both creating the folder structure and authenticating with Plotly's server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:31:38.437974Z",
     "start_time": "2021-04-13T03:31:38.422550Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Directory to Save Figures to\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.mkdir(\"figures\")\n",
    "\n",
    "# Create Directory to Save Interactive plots to\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.mkdir(\"plots\")\n",
    "    \n",
    "# Create Directory to Save gifs\n",
    "if not os.path.exists(\"gifs\"):\n",
    "    os.mkdir(\"gifs\")\n",
    "    \n",
    "# Retreiving API Keys from OS\n",
    "PLOTLY_API_KEY = os.environ.get('PLOTLY_API_KEY')\n",
    "PLOTYLY_USERNAME = 'rhumphreys2017'\n",
    "\n",
    "# Log into chart studio for uploading plots\n",
    "chart_studio.tools.set_credentials_file(username=PLOTYLY_USERNAME, api_key=PLOTLY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data-source\"></a>\n",
    "<h1>1. Data Source</h1>\n",
    "\n",
    "To perform accurate simulations, it is essential to have some real-world satellite data as the starting point for modeling the fragmentation event. Therefore, this notebook is a file containing NORAD Two-Line Element Sets (TLE) acquired from [CelesTrak](https://celestrak.com/NORAD/elements/). The rest of this section involves importing said data and discussing how the TLE data structure functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.1 Loading TLE Data</h3>\n",
    "\n",
    "TLE's are standardized data structures that contain the orbital elements used to describe Earth-orbiting objects for a given point in time. Most importantly, they are used to determine where a given object will be at any given time. Thus, it is a valuable tool for analyzing potential orbital collisions as well as tracking orbital debris.\n",
    "\n",
    "To acquire the most recent information about all objects being tracked in Earth orbit is recommended to download the latest TLE data from CelesTrak. This file comes in the form of a `.txt` file that first must be parsed to use while programming. While it is possible to manually parse all of the data from the TLEs using [Regular expression operations](https://docs.python.org/3/library/re.html), for this notebook, I will be utilizing the `skyfield` python module as it has the built-in functionality to handle this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:31:41.682958Z",
     "start_time": "2021-04-13T03:31:40.796973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Opening the .txt file\n",
    "import importlib\n",
    "from odap.Satellite import Satellite\n",
    "with open(sys.path[1] + \"/data/3le.txt\") as f:\n",
    "    txt = f.read()\n",
    "    \n",
    "# Using regular expression to perform basic parsing of the 3le.txt file\n",
    "# Returns and array of arrays where each subarray contains three strings\n",
    "# corresponding to each line of th TLE\n",
    "tles = np.array([tle for tle in re.findall('(.*?)\\n(.*?)\\n(.*?)\\n', txt)])\n",
    "\n",
    "# TODO: Validate Satellite w/ name OV1-4\n",
    "satellites = [Satellite(tle) for tle in tles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Select orbital object for analysis</h3>\n",
    "\n",
    "Now that we have an array containing Satellite objects, we can utilize NumPy to find a satellite that satisfies whatever criterion we are looking for. For example, we may want to simulate a fragmentation event for a satellite with a low semi-major axis or a high eccentricity. To keep things simple, I selected a satellite using the name assigned to it by NORAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:32:06.383448Z",
     "start_time": "2021-04-13T03:32:06.342152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'OXP 1',\n",
       " 'num': '22489',\n",
       " 'classification': 'U',\n",
       " 'year': '93',\n",
       " 'launch': '009',\n",
       " 'piece': 'A  ',\n",
       " 'epoch_year': '22',\n",
       " 'epoch_day': '022.31925541',\n",
       " 'ballistic_coefficient': ' .00000301',\n",
       " 'mean_motion_dotdot': ' 00000-0',\n",
       " 'bstar': ' 32666-4',\n",
       " 'ephemeris_type': '0',\n",
       " 'element_number': '9995',\n",
       " 'inclination': ' 24.9661',\n",
       " 'raan': ' 33.9038',\n",
       " 'eccentricity': '0041192',\n",
       " 'aop': ' 88.0406',\n",
       " 'mean_anomaly': '272.4819',\n",
       " 'mean_motion': '14.45058525',\n",
       " 'epoch_rev': '52836'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing an array that contains the names of all the satellites in our dataset\n",
    "# Note: The name formatting of all satellites starts with \"0 \",\n",
    "#       thus we slice the String to cut the 0.\n",
    "names = np.array([sat.name for sat in satellites])\n",
    "\n",
    "# Search the name array for the index of desired satellite\n",
    "i = np.argwhere(names == \"OXP 1\").flatten()[0]\n",
    "\n",
    "# Retrieve that satellite object from the `satellites` array using the found index\n",
    "satellite = satellites[i]\n",
    "\n",
    "satellite.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a specific satellite object, we can access all of the relevant information easily by utilizing the attributes specified by the `Satellite` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: OXP 1\n",
      "Mean Anomaly:  272.4819\n",
      "BSTAR drag:   32666-4\n"
     ]
    }
   ],
   "source": [
    "# Displaying the TLE data for the retrieved satellite\n",
    "print(\"Name: \" + satellite.name)\n",
    "print(\"Mean Anomaly: \", satellite.mean_anomaly)\n",
    "print(\"BSTAR drag: \", satellite.bstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:13:24.736191Z",
     "start_time": "2021-04-13T02:13:24.731596Z"
    }
   },
   "source": [
    "<a class=\"anchor\" id=\"fragmentation\"></a>\n",
    "# 2. Fragmentation Event Modeling\n",
    "\n",
    "A satellite breakup model is a mathematical model used to describe the outcome of a satellite breakup due to an explosion or collision. A satellite breakup model should describe the size, area-to-mass (AM) ratio, and the ejection velocity of each fragment produced in the satellite breakup. The most easily accessible literature model is the [NASA Standard breakup model](https://www.sciencedirect.com/science/article/abs/pii/S0273117701004239). This model is implemented in ODAP in `generate_debris.py`.\n",
    "\n",
    "In the following subsections, ODAP is utilized to simulate an explosion event and a collision event. Additionally, some information about how the NASA Standard Breakup Model works is provided. For additional information it is recomended to refer to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Exploring the NASA Breakup model\n",
    "\n",
    "The NASA standard breakup model uses experimental observations performed both on Earth and in orbit to characterize the breakup using statistical distributions. The choice to use statistical distributions is a result of the stochastic nature of the breakup event, meaning it would be impossible to reproduce the same circumstances each time. By using a statistical distribution and sampling from it we can more accurately represent the fragments that would be generated during a collision or explosion.\n",
    "\n",
    "### Characteristic Length\n",
    "\n",
    "To account for the different characteristics of each fragment of debris, the statistical distributions must be expressed as a function of some independent variable. In the latest version of the NASA breakup model, this variable is called the characteristic length, denoted $L_c$. By defining the distributions using characteristic length we ensure that the mass, area, and velocity of each fragment are not constant for all debris with the same characteristic length. The implementation of the characteristic length distribution can be cumbersome to follow. As such, a flow chart illustrating the steps of the algorithm is provided below.\n",
    "<br>\n",
    "<img src=\"../images/diagram1.png\" width=400 height=400 />\n",
    "\n",
    "### Area to Mass Distribution\n",
    "\n",
    "The area-to-mass ratio, A/M , for fragments is a distribution that was based on analysis of thousands of fragmentation debris and provides us with a method to determine the mass of each fragment of debris. The discrete distributions were found by using a $\\chi^2$ fit to orbital decay characteristics for 1,780 upper stage explosion fragments, and similar data was developed for spacecraft fragments. Each type of debris producer - rocket bodies (RB), spacecraft (SC), satellites (SAT) - will produce different size debris. As such, the distribution that determines the area to mass ratio has three variants. All three are based on a normal distribution but use different expressions for determining the mean and standard deviation of the distribution.\n",
    "\n",
    "For example, small objects with $L_c < 8$cm, SAT, the $A/M$ distribution is expressed as\n",
    "\n",
    "\\begin{equation}\n",
    "\tD_{A/M}(\\lambda_c, \\chi) = \\mathcal{N}(\\mu_{A/M}(\\lambda_c), \\sigma_{A/M}(\\lambda_c), \\chi).\n",
    "\\end{equation}\n",
    "\n",
    "$D_{A/M}$ is the distribution function of $\\chi$ as a function of $\\lambda_c$, where\n",
    "\\begin{align}\n",
    "\t\\lambda_c &= \\log_{10}(L_c),\\\\\n",
    "\t\\chi &= \\log_{10}(A/M)\n",
    "\\end{align}\n",
    "\n",
    "$\\mathcal{N}$ is the normal distribution function with mean $\\mu_{A/M}$ and standard deviation $\\sigma_{A/M}$, where\n",
    "\n",
    "\\begin{align}\n",
    "\t \\mu_{A/M} &= \\begin{cases} \n",
    "\t\t-0.3, & \\lambda_c\\leq -1.75 \\\\\n",
    "\t\t-0.3 - 1.4(\\lambda_c + 1.75), & -1.75 < \\lambda_c <-1.25 \\\\\n",
    "\t\t-1.0, & \\lambda_c \\geq -1.25 \n",
    "\t\\end{cases}\\\\\n",
    "\t\\text{and}\\\\\n",
    "\t\\sigma_{A/M} &= \\begin{cases} \n",
    "\t\t0.2, & \\lambda_c \\leq -3.5 \\\\\n",
    "\t\t0.2 + 0.1333(\\lambda_c + 3.5) & \\lambda_c > -3.5 \\\\\n",
    "\t\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Every fragment of debris has a corresponding $A/M$ distribution since both $\\mu_{A/M}$ and $\\sigma_{A/M}$ are functions of $\\lambda_c$. To determine the corresponding $A/M$ ratio for each debris, a random value is drawn from the distribution. This accounts for stochastic nature of breakup events mentioned previously. \n",
    "\n",
    "\n",
    "The $A/M$ ratio alone does not provide enough information to determine both the area and mass of a fragment. As such, the average cross-sectional area, $A$, can also be obtained through a one-to-one correspondence with $L_c$ using the following expression:\n",
    "\n",
    "\\begin{align}\n",
    "\tA_x = \\begin{cases}\n",
    "\t\t0.540424 * L_c^2 & \\text{where } L_c < 0.00167 \\text{ m} \\\\\n",
    "\t\t0.556945 * L_c^{2.0047077} & \\text{where } L_c \\geq 0.00167 \\text{ m} \\\\\n",
    "\t\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Utilizing both the $A/M$ ratio and the cross sectional area $A$, we can now obtain the mass $M$ easily using\n",
    "$M = A_x / (A/M)$.\n",
    "\n",
    "### Change in Velocity Distribution\n",
    "\n",
    "The differential amount of velocity that each fragment will gain due to the breakup event is determined in a similar manner to the $A/M$ ratio. The notable differences are that the distribution is now a log-normal distribution and that an additional check is implemented to ensure that extremely high ejection velocities are not included in the case of collisions. \n",
    "\n",
    "More explicitly, the velocity check is performed by sampling a value from the velocity distribution and checking if it is lower than $1.3v_c$, where $v_c$ is the relative collision velocity. If the value fails the check then new values are drawn until the check is passed.\n",
    "\n",
    "The change in velocity, $\\Delta v$, is modeled by log-normal distribution that is function of the $A/M$ ratio by\n",
    "\n",
    "\\begin{equation}\n",
    "\tD_{\\Delta v}= \\mathcal{N}(\\mu_{v}(\\chi), \\sigma_{v}(\\chi), \\xi)\n",
    "\\end{equation}\n",
    "where for SAT breakups \\begin{align}\n",
    "\t&\\xi = \\log_{10}(\\Delta v),\\\\\n",
    "\t&\\chi = \\log_{10}(A/M),\\\\\n",
    "\t&\\mu_{v}(\\chi) = 0.2\\chi+1.85,\\\\\n",
    "\t&\\sigma_{v}(\\chi) = 0.4,\n",
    "\\end{align}\n",
    "\n",
    "### Additional information\n",
    "\n",
    "All of the functionality required for modeling RB, SC, and SAT fragmentation events is included in ODAP. Speciffically, the implementation details can be found in `generate_debris.py`. It is recomended that for additional information you consult [my thesis](), [letizia](), [another](), [another]().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:14:08.714051Z",
     "start_time": "2021-04-13T02:14:08.708765Z"
    }
   },
   "source": [
    "### 2.1.1 Modeling a rocket body explosion\n",
    "\n",
    "Now that the details of the NASA Breakup Model have been specified, we can begin to simulate some fragmentation events. This first example shows how to simulate an explosion of a 1000 kg rocket body. An outputs some information about the debris cloud generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimulationType' from 'odap.SimulationConfiguration' (/Users/reecehumphreys/Developer/Personal/ODAP/notebooks/../odap/SimulationConfiguration.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bt/zqdn15p55q9cpvhg66r8f77w0000gn/T/ipykernel_20266/1128424390.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0modap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSimulationConfiguration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/odap-env/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"spec not found for the module {name!r}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;31m# The module may have replaced itself in sys.modules!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/odap-env/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/odap-env/lib/python3.9/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/odap-env/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/Developer/Personal/ODAP/notebooks/../odap/FragmentationEvent.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSatellite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSatellite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mSimulationConfiguration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimulationType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimulationConfiguration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFragmentationEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_inputMass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SimulationType' from 'odap.SimulationConfiguration' (/Users/reecehumphreys/Developer/Personal/ODAP/notebooks/../odap/SimulationConfiguration.py)"
     ]
    }
   ],
   "source": [
    "### Testing Fragmentation Event\n",
    "import odap.FragmentationEvent as event\n",
    "import odap.SimulationConfiguration as configuration\n",
    "\n",
    "reload(configuration)\n",
    "reload(event)\n",
    "\n",
    "\n",
    "config = configuration.SimulationConfiguration('../data/testData.ini')\n",
    "event = event.FragmentationEvent(config)\n",
    "event.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:44:40.503265Z",
     "start_time": "2021-04-13T02:44:35.833034Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Explosion: \n",
    "#\n",
    "# Simulating an explosion of a 1000 kg rocket body. Note that since the object is\n",
    "# exploding there is no projectile thus `m_projectile` is 0 and `v_impact` is 0.\n",
    "\n",
    "\n",
    "m_target        = 1000      # [kg]. The mass of the target\n",
    "m_projectile    = 0         # [kg]. The mass of the projectile\n",
    "v_impact        = 0         # [km s^-1]. The relative impact velocity\n",
    "is_catastrophic = True \n",
    "is_explosion    = True\n",
    "object_type     = debris_category.rb\n",
    "\n",
    "# `L_c` [m], `areas` [m^2], `masses` [kg], `AM` []\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target,\n",
    "                                          m_projectile,\n",
    "                                          v_impact,\n",
    "                                          is_catastrophic,\n",
    "                                          object_type,\n",
    "                                          is_explosion)\n",
    "\n",
    "# Constructing bins from 1e-3 [m] to 1 [m] and populating histogram\n",
    "# with generated characteristic length data\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf]\n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df = pd.DataFrame(ch)\n",
    "\n",
    "# Constructing bins from 1e3 [g] to inf [g] and populating histogram\n",
    "# with generated mass data\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(masses*1e3, bins=bins) # grams\n",
    "ch = [ { f'>{bins[i]}g':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df2 = pd.DataFrame(ch)\n",
    "\n",
    "# Constructing bins from 1e4 [cm^2] to inf [cm^2] and populating histogram\n",
    "# with generated mass data\n",
    "h,b = np.histogram(areas*1e4, bins=bins) # cm^2\n",
    "ch = [ { f'>{bins[i]}cm^2':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df3 = pd.DataFrame(ch)\n",
    "\n",
    "# # # VELOCITY DATA (A bit janky currently, always need to specify v_c event for explosions)\n",
    "deltaV = 10**np.array(gd.distribution_deltaV(AM, 5, True)) # [m·s^-1]\n",
    "bins = [100, np.inf]\n",
    "h,b = np.histogram(deltaV, bins=bins)\n",
    "ch = [ { f'>{bins[i]}km/s':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df4 = pd.DataFrame(ch)\n",
    "\n",
    "# Showing Distribution results for explosion event\n",
    "results = pd.concat([df, df2, df3, df4], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Modeling a rocket body collision\n",
    "\n",
    "Additionally, we can also use ODAP to simulate collision events. The only difference is specifying a non zero projectile mass and a non zero relative impact velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:44:49.401490Z",
     "start_time": "2021-04-13T02:44:45.246256Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Collision: \n",
    "#\n",
    "# Simulating an collision between a 1000 kg rocket body and a 10 kg projectile. \n",
    "\n",
    "gd = reload(gd)\n",
    "\n",
    "m_target        = 1000       # [kg]\n",
    "m_projectile    = 10         # [kg]\n",
    "v_impact        = 10         # [km s^-1]\n",
    "is_catastrophic = True \n",
    "is_explosion    = False\n",
    "object_type     = debris_category.rb\n",
    "\n",
    "# `L_c` [m], `areas` [m^2], `masses` [kg], `AM` []\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target,\n",
    "                                          m_projectile,\n",
    "                                          v_impact,\n",
    "                                          is_catastrophic,\n",
    "                                          object_type,\n",
    "                                          is_explosion)\n",
    "\n",
    "# Constructing bins from 1e-3 [m] to 1 [m] and populating histogram\n",
    "# with generated characteristic length data\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf] \n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df = pd.DataFrame(ch)\n",
    "\n",
    "# Constructing bins from 1e3 [g] to inf [g] and populating histogram\n",
    "# with generated mass data\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(masses*1e3, bins=bins) # grams\n",
    "ch = [ { f'>{bins[i]}g':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df2 = pd.DataFrame(ch)\n",
    "\n",
    "# Constructing bins from 1e4 [cm^2] to inf [cm^2] and populating histogram\n",
    "# with generated mass data\n",
    "h,b = np.histogram(areas*1e4, bins=bins) # cm^2\n",
    "ch = [ { f'>{bins[i]}cm^2':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df3 = pd.DataFrame(ch)\n",
    "\n",
    "# # VELOCITY DATA (A bit janky currently, always need to specify v_c event for explosions)\n",
    "deltaV = 10**np.array(gd.distribution_deltaV(AM, v_impact, is_explosion)) # [m·s^-1]\n",
    "bins = [1e3, np.inf]\n",
    "h,b = np.histogram(deltaV, bins=bins)\n",
    "ch = [ { f'>{bins[i]}m/s':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df4 = pd.DataFrame(ch)\n",
    "\n",
    "results = pd.concat([df, df2, df3, df4], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:22:17.012069Z",
     "start_time": "2021-04-13T02:22:16.999045Z"
    }
   },
   "source": [
    "### 2.1.2 Visualizing the results\n",
    "\n",
    "Now that we have some data about a breakup event, we can begin to visualize the various variables to understand how closely ODAP models the fragmentation event compared to the results from other available research data.\n",
    "\n",
    "This is accomplished by utilizing Plotly to generate figures. As such, most of the bellow cell involves setting appropriate layouts to the figures. The primary purpose of which is to illustrate how we can take the fragmentation data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create logarithmic spaced bins\n",
    "def create_log_bins(values, nbins=100):\n",
    "    bins = np.geomspace(values.min(), values.max(), nbins)\n",
    "    a = bins[1]/bins[0]\n",
    "    bins = np.concatenate([[bins[0]/a], bins,[bins[-1]*a]])\n",
    "    return bins\n",
    "\n",
    "# Specify a common Layout theme\n",
    "layout = dict(\n",
    "    autosize=False,\n",
    "    width=500,\n",
    "    height=500,\n",
    "    template = 'plotly_white',\n",
    "    yaxis = dict(\n",
    "        range=[0,8e5],\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e'\n",
    "    ),\n",
    "    legend=dict(\n",
    "        y=0.5,\n",
    "        traceorder='reversed',\n",
    "        font=dict(\n",
    "            size=16\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Characteristic Length Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Histogram\n",
    "h, b = np.histogram(L_c, bins=create_log_bins(L_c))\n",
    "# Make figure\n",
    "fig = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(\n",
    "    title = 'Characteristic Length Distribution',\n",
    "    xaxis_title=r'$\\log_{10}(L_{c}\\:[m])$',\n",
    "    yaxis_title=r'$N_f$'\n",
    ")\n",
    "\n",
    "# Save the Plot to the figures folder\n",
    "fig.write_image(\"figures/N_f_vs_L_c.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig, filename=\"Characteristic Length Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Areas Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Histogram\n",
    "h, b = np.histogram(areas, bins=create_log_bins(areas))\n",
    "\n",
    "# Make figure\n",
    "fig2 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "fig2.update_xaxes(type=\"log\")\n",
    "fig2.update_layout(\n",
    "    title = 'Area distribution',\n",
    "    xaxis_title=r'$\\log_{10}(A\\:[m^2])$',\n",
    "    yaxis_title=r'$N_f$',\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig2.write_image(\"figures/N_f_vs_A.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig2, filename=\"Area distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Mass Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Histogram\n",
    "h, b = np.histogram(masses, bins=create_log_bins(masses))\n",
    "\n",
    "# Make figure\n",
    "fig3 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "fig3.update_xaxes(type=\"log\")\n",
    "fig3.update_layout(\n",
    "    title = 'Mass Distribution',\n",
    "    xaxis_title=r'$\\log_{10}(M\\:[kg])$',\n",
    "    yaxis_title=r'$N_f$'\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig3.write_image(\"figures/N_f_vs_M.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig3, filename=\"Mass Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing Velocity Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Histogram\n",
    "h, b = np.histogram(deltaV, bins=create_log_bins(deltaV))\n",
    "\n",
    "# Make figure\n",
    "fig4 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "\n",
    "# Update figure\n",
    "fig4.update_xaxes(type=\"log\")\n",
    "fig4.update_layout(\n",
    "    title = 'Velocity distribution',\n",
    "    xaxis_title=r'$\\log_{10}(V\\:[ms^-1])$',\n",
    "    yaxis_title=r'$N_f$',\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig4.write_image(\"figures/N_f_vs_V.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig4, filename=\"Velocity distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:04:58.954987Z",
     "start_time": "2021-04-13T02:04:58.934321Z"
    }
   },
   "source": [
    "## 2.2 Performing a Fragmentation Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:18.050293Z",
     "start_time": "2021-04-13T03:32:28.591786Z"
    }
   },
   "outputs": [],
   "source": [
    "# Performing fragmentation event\n",
    "ts = load.timescale(builtin=True)\n",
    "t_fragmentation = ts.now()\n",
    "\n",
    "print(type(ts))\n",
    "print(type(t_fragmentation))\n",
    "\n",
    "geocentric      = satellite.at(t_fragmentation)\n",
    "init_position   = geocentric.position.m\n",
    "\n",
    "m_target         = 250   # [kg] (Approx. mass of starlink sat)\n",
    "m_projectile     = 200     # [kg]\n",
    "v_impact         = 2   # [km·s^-1] (Measured relative to the target) (Needs to be in km·s^-1)\n",
    "is_catastrophic  = False\n",
    "is_explosion     = False\n",
    "\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, m_projectile, v_impact, is_catastrophic, debris_category.sc, is_explosion)\n",
    "deltaV = np.array(gd.distribution_deltaV(AM, v_impact, False)) # Returns as [km·s^-1]\n",
    "deltaV = deltaV * 1e3    #[m·s^-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:07:43.835833Z",
     "start_time": "2021-04-13T02:07:43.829932Z"
    }
   },
   "source": [
    "#### 2.1.3 Retriving Cartesian coordinates of debris fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:40.944054Z",
     "start_time": "2021-04-13T03:33:40.490279Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "init_position = geocentric.position.m\n",
    "deb_positions       = np.empty((len(AM), 3))\n",
    "deb_positions[:, :] = init_position[None,:]\n",
    "deb_velocities      = gd.velocity_vectors(len(AM), geocentric.velocity.m_per_s, deltaV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:09:37.908615Z",
     "start_time": "2021-04-13T02:09:37.901200Z"
    }
   },
   "source": [
    "#### 2.1.4 Converting coordinates to Keplerian elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:44.843674Z",
     "start_time": "2021-04-13T03:33:42.767256Z"
    }
   },
   "outputs": [],
   "source": [
    "keplerian_state     = ct.rv2coe(deb_positions, deb_velocities, planetary_data.earth['mu'])\n",
    "\n",
    "# Removing fragments that would renter earth\n",
    "periapsis           = keplerian_state[0, :] * (1 - keplerian_state[1, :])\n",
    "I                   = np.argwhere(periapsis > planetary_data.earth['radius'])\n",
    "keplerian_state     = np.squeeze(keplerian_state[:, I])\n",
    "areas               = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses              = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Ring Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:47.275860Z",
     "start_time": "2021-04-13T03:33:47.250686Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shrink number of debris being used\n",
    "indexes = np.random.default_rng().choice(keplerian_state.shape[1], size=1000, replace=False)\n",
    "\n",
    "ks = keplerian_state[:, indexes]\n",
    "masses = masses[indexes]\n",
    "areas = areas[indexes]\n",
    "deb_positions = deb_positions[indexes, :]\n",
    "deb_velocities = deb_velocities[indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:30.754652Z",
     "start_time": "2021-04-13T03:33:50.015837Z"
    }
   },
   "outputs": [],
   "source": [
    "import Perturbations as OP\n",
    "import planetary_data as pd\n",
    "from Perturbations import null_perts\n",
    "\n",
    "# Cleanup states to remove any fragments that would deorbit, given no perturbations\n",
    "periapsis     = ks[0, :] * (1 - ks[1, :])\n",
    "I             = np.argwhere(periapsis > pd.earth['radius'])\n",
    "ks_pruned     = np.squeeze(ks[:, I])\n",
    "T             = ks_pruned[8, :]\n",
    "areas_pruned  = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses_pruned = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "\n",
    "# Propagate orbit for a period of time\n",
    "perts = null_perts()\n",
    "perts['aero'] = True\n",
    "perts['J2']   = True\n",
    "op = OP.OrbitPropagator(ks_pruned, areas_pruned, masses_pruned, [0, 1000*np.ceil(max(T))], 60*30, perts=perts)\n",
    "op.propagate_orbit()\n",
    "\n",
    "# Get the cartesian state representation\n",
    "cartesian_states = op.cartesian_representation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T01:17:23.880120Z",
     "start_time": "2021-04-09T01:17:23.841714Z"
    },
    "scrolled": true
   },
   "source": [
    "<h4>3.4.2 Particle Debris flux</h4>\n",
    "\n",
    "Using a particle flux to determine when the fragments of the debris have finished the formation of the ring. Indicating the end of the first phase of the debris cloud formation. This is accomplished by creating an xz plane and detecting when particles have switched from one side to the other. This approach will cause a peak as fragments pass through that becomes uniform as the debris becomes uniformly spread out.\n",
    "\n",
    "<h4>3.4.3 Convergence of the flux</h4>\n",
    "\n",
    "The next step is determining when the fragments have ended the torroid formation phase. This occurs when the fragments are approximately uniformally spread out. We can check to see when the flux meets a convergence criterion to determine when this happens.\n",
    "\n",
    "Now that the band has formed, we can shift away from propagating the exact position of each fragments and inplace propgate their changes in eccentricity and semi major axis due to drag. To do this first we must get the final states of the debris after the band has formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:34.645680Z",
     "start_time": "2021-04-13T03:34:34.433500Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "from dateutil import tz\n",
    "\n",
    "def fragmentation_flux(X):\n",
    "    return np.sum((X[:-1, :, 1] < 0) & (X[1:, :, 1] > 0), axis=1)\n",
    "    \n",
    "position = cartesian_states[:, 0, :, :]\n",
    "flux = fragmentation_flux(position)\n",
    "\n",
    "w = 100 # Window of points to look at\n",
    "tol = 5\n",
    "convergence_ratio = np.array([np.var(flux[i:i+w])/np.mean(flux[i:i+w]) for i in range(len(flux))])    \n",
    "intersection_index = np.argwhere(convergence_ratio <= tol).flatten()[0]\n",
    "\n",
    "# datetimes\n",
    "t_flux = t_fragmentation.utc_datetime() + np.array(range(len(flux))) * datetime.timedelta(minutes = 5)\n",
    "\n",
    "# Removing last window from `t_flux`, `flux`, and `convergence_ratio` bc. not well defined for last values\n",
    "t_flux = t_flux[:-w]\n",
    "flux = flux[:-w]\n",
    "convergence_ratio = convergence_ratio[:-w]\n",
    "\n",
    "# Pruning data to the end of the ring formation\n",
    "cs_toroid = cartesian_states[:intersection_index, :, :, :]\n",
    "ks_toroid = op.states[0:intersection_index, :, :]\n",
    "op.states = ks_toroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Band Formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Drag Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:47:19.616099Z",
     "start_time": "2021-04-13T03:47:19.270256Z"
    }
   },
   "outputs": [],
   "source": [
    "import Aerodynamics as aero\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "upper_bound = 900                                #[km]\n",
    "altitudes   = np.arange(0, upper_bound, 1)      #[km]\n",
    "rho         = aero.atmosphere_density(altitudes) #[kg·m^-3]\n",
    "\n",
    "I_standard = np.argwhere(altitudes == 25).flatten()[0]\n",
    "I_cira    = np.argwhere(altitudes  == 500).flatten()[0]\n",
    "\n",
    "# Plotting the Exponential Atmospheric Model\n",
    "\n",
    "layout = go.Layout(\n",
    "    title        = go.layout.Title(text='Altitude (z) vs. Atmospheric Density (ρ)',\n",
    "                                   x=0.5),\n",
    "    xaxis_title  = 'z [km]',\n",
    "    yaxis_title  = '$\\log_{10}(\\\\rho\\:[kg·m^{-3}])$',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=altitudes[:I_standard], y=rho[:I_standard],\n",
    "                    mode='lines',\n",
    "                    name='U.S Standard Atmosphere'),\n",
    "    go.Scatter(x=altitudes[I_standard:I_cira], y=rho[I_standard:I_cira],\n",
    "                    mode='lines',\n",
    "                    name='CIRA-72'),\n",
    "    go.Scatter(x=altitudes[I_cira:], y=rho[I_cira:],\n",
    "                    mode='lines',\n",
    "                    name='CIRA-72 with T_infinity = 1000K')\n",
    "]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "\n",
    "fig.write_image(\"figures/Atmospheric_Density_v_Altitude.png\", width=500, height=500, scale=2)\n",
    "f2 = go.FigureWidget(fig)\n",
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Applying Perturbations to Satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:48:45.470540Z",
     "start_time": "2021-04-13T02:48:43.740049Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import iv\n",
    "from scipy import integrate\n",
    "import Aerodynamics as aero\n",
    "\n",
    "op.tspan[-1] = 3600*24*365*3\n",
    "op.dt = 3600*24\n",
    "de, da, di, dOmega, domega, dnu, dp = op.propagate_perturbations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 FLux plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:57.346240Z",
     "start_time": "2021-04-13T03:34:50.443218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Flux v. Time plot\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='$\\\\text{Flux}\\:(\\\\Phi)\\:\\\\text{vs. Time }(t)$',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = '$\\\\text{ Number of fragments passing XZ plane, }\\Phi\\:$',\n",
    "    template     = 'plotly_white'\n",
    ")\n",
    "\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=t_flux, y=flux,\n",
    "               mode='lines',\n",
    "               name='Flux'),\n",
    "    go.Scatter(x=[t_flux[intersection_index], t_flux[intersection_index]], y=[0, np.max(flux)],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Convergence')\n",
    "]\n",
    "\n",
    "fig1 = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Stopping data to have half before intersection index and half after\n",
    "index_stop = intersection_index * 2\n",
    "if index_stop > len(flux) - 1 : index_stop = len(flux) - 1\n",
    "fig1.update_layout(xaxis_range=[t_flux[0],t_flux[index_stop]])\n",
    "\n",
    "# Saving plot as an image and uploading it to plotly\n",
    "fig1.write_image(\"figures/Flux_v_Time.png\", width=500, height=500, scale=2)\n",
    "#py.iplot(fig1, filename=\"Flux v. Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Convergence Ratio plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:35:40.893879Z",
     "start_time": "2021-04-13T03:35:40.588308Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating Convergence Ratio v. Time plot\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='Convergence ratio vs. Time (t)',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = 'Convergence ratio []',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "data = [\n",
    "    go.Scatter(x=t_flux, y=convergence_ratio,\n",
    "               mode='lines',\n",
    "               name='Convergence ratio'),\n",
    "    go.Scatter(x=[t_flux[intersection_index], t_flux[intersection_index]], y=[0, np.max(flux)],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Convergence time'),\n",
    "    go.Scatter(x=[t_flux[0], t_flux[-1]], y=[tol, tol],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Tolerance'),\n",
    "]\n",
    "fig2 = go.Figure(data=data, layout=layout)\n",
    "fig2.update_yaxes(type=\"log\")\n",
    "fig2.write_image(\"figures/Convergence_Ratio_v_Time.png\", width=500, height=500, scale=2)\n",
    "#py.iplot(fig2, filename=\"Convergence Ratio v. Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ring visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:20:01.019781Z",
     "start_time": "2021-04-13T03:19:27.522113Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pandas\n",
    "\n",
    "spherical_earth_map = np.load('map_sphere.npy') \n",
    "\n",
    "pos_toroid = cs_toroid[:, 0, :, :]/1e3\n",
    "N_timesteps = pos_toroid.shape[0]\n",
    "N_fragments = pos_toroid.shape[1]\n",
    "r_E = op.cb['radius'] / 1e3\n",
    "xm, ym, zm = spherical_earth_map.T * r_E\n",
    "\n",
    "# Converting data to pandas dataframe\n",
    "df = pandas.DataFrame()\n",
    "# *** Update this if chnage timestep in initial orbit propagation ***\n",
    "dt = 60 * 5 #[s]\n",
    "# Want to show the evolution in 30 min\n",
    "timesteps = np.arange(0,N_timesteps, 6)\n",
    "\n",
    "for t in timesteps:   \n",
    "    step = t*np.ones_like(N_timesteps)\n",
    "    time = dt * step / 60 #[min]\n",
    "    d = {'X': pos_toroid[t, :, 0],\n",
    "         'Y': pos_toroid[t, :, 1],\n",
    "         'Z':pos_toroid[t, :, 2],\n",
    "         'Min.': time,\n",
    "         'a': ks_toroid[t, 0, :]/1e3,\n",
    "         'e': ks_toroid[t, 1, :],\n",
    "         'i': ks_toroid[t, 2, :],\n",
    "        }\n",
    "    df = pandas.concat([df, pandas.DataFrame(data=d)])\n",
    "\n",
    "# Creating visual\n",
    "def spheres(size, clr, dist=0): \n",
    "\n",
    "    # Set up 100 points. First, do angles\n",
    "    theta = np.linspace(0,2*np.pi,100)\n",
    "    phi = np.linspace(0,np.pi,100)\n",
    "\n",
    "    # Set up coordinates for points on the sphere\n",
    "    x0 = dist + size * np.outer(np.cos(theta),np.sin(phi))\n",
    "    y0 = size * np.outer(np.sin(theta),np.sin(phi))\n",
    "    z0 = size * np.outer(np.ones(100),np.cos(phi))\n",
    "\n",
    "    # Set up trace\n",
    "    trace= go.Surface(x=x0, y=y0, z=z0, colorscale=[[0,clr], [1,clr]])\n",
    "    trace.update(showscale=False)\n",
    "\n",
    "    return trace\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=df,\n",
    "    x='X',\n",
    "    y='Y',\n",
    "    z='Z',\n",
    "    title='Evolution of debris cloud to toroid formation',\n",
    "    hover_data={'Min.': False, 'X': False, 'Y':False, 'Z':False, 'a':':.1f', 'e':':.4f','i':':.1f' },\n",
    "    height=800,                 # height of graph in pixels\n",
    "    width =800,\n",
    "    animation_frame='Min.',   # assign marks to animation frames\n",
    "    range_x=[-r_E - 1000,r_E + 1000],\n",
    "    range_z=[-r_E - 1000,r_E + 1000],\n",
    "    range_y=[-r_E - 1000,r_E + 1000],\n",
    "\n",
    ")\n",
    "fig.update_traces(marker={'size': 3})\n",
    "# Add Earth\n",
    "earth=spheres(r_E, '#F0FFFF', 0) # Earth\n",
    "#fig.add_trace(go.Scatter3d(x=xm, y=ym, z=zm, mode='lines', line=dict(color=zm, colorscale='Viridis')))\n",
    "fig['layout']['scene']['aspectmode'] = 'cube'\n",
    "fig.add_trace(earth)\n",
    "fig.update_layout(transition = {'duration': 2000})\n",
    "fig.write_html(\"plots/ring.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Band visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:11.785292Z",
     "start_time": "2021-04-13T02:50:52.771515Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.zeros_like(da) # The params set to 0 dont matter for converting to rv\n",
    "ks_propagated = np.swapaxes(np.stack([da, de, di, dOmega, domega, temp, dnu, dp, temp, temp]).T, 1, 2)\n",
    "ks_final = np.concatenate([ks_toroid, ks_propagated])\n",
    "op.states = ks_final\n",
    "cs_final = op.cartesian_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:21.308114Z",
     "start_time": "2021-04-13T02:51:15.298065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import plotly.express as px\n",
    "\n",
    "pos_toroid = cs_final[cs_toroid.shape[0]-1:, 0, :, :]/1e3\n",
    "N_timesteps = pos_toroid.shape[0]\n",
    "N_fragments = pos_toroid.shape[1]\n",
    "r_E = op.cb['radius'] / 1e3\n",
    "\n",
    "\n",
    "# Converting data to pandas dataframe\n",
    "df = pandas.DataFrame()\n",
    "# *** Update this if chnage timestep in initial orbit propagation ***\n",
    "dt = 60 * 5 #[s]\n",
    "# Want to show the evolution in 1 day steps\n",
    "timesteps = np.arange(0,N_timesteps, 5)\n",
    "\n",
    "for t in timesteps:   \n",
    "    step = t*np.ones_like(N_timesteps)\n",
    "    time = step  #[day]\n",
    "    d = {'X': pos_toroid[t, :, 0],\n",
    "         'Y': pos_toroid[t, :, 1],\n",
    "         'Z':pos_toroid[t, :, 2],\n",
    "         'Day': time,\n",
    "        }\n",
    "    df = pandas.concat([df, pandas.DataFrame(data=d)])\n",
    "\n",
    "def spheres(size, clr, dist=0): \n",
    "\n",
    "    # Set up 100 points. First, do angles\n",
    "    theta = np.linspace(0,2*np.pi,100)\n",
    "    phi = np.linspace(0,np.pi,100)\n",
    "\n",
    "    # Set up coordinates for points on the sphere\n",
    "    x0 = dist + size * np.outer(np.cos(theta),np.sin(phi))\n",
    "    y0 = size * np.outer(np.sin(theta),np.sin(phi))\n",
    "    z0 = size * np.outer(np.ones(100),np.cos(phi))\n",
    "\n",
    "    # Set up trace\n",
    "    trace= go.Surface(x=x0, y=y0, z=z0, colorscale=[[0,clr], [1,clr]])\n",
    "    trace.update(showscale=False)\n",
    "\n",
    "    return trace\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=df,\n",
    "    x='X',\n",
    "    y='Y',\n",
    "    z='Z',\n",
    "    title='Evolution of debris cloud to Band formation',\n",
    "    #labels={'Years in school (avg)': 'Years Women are in School'},\n",
    "    #hover_data={'Min.': False, 'X': False, 'Y':False, 'Z':False, 'a':':.1f', 'e':':.4f','i':':.1f' },\n",
    "    #hover_name='Orbital Elements',        # values appear in bold in the hover tooltip\n",
    "    height=800,                 # height of graph in pixels\n",
    "    width =800,\n",
    "    animation_frame='Day',   # assign marks to animation frames\n",
    "    range_x=[-r_E - 1000,r_E + 1000],\n",
    "    range_z=[-r_E - 1000,r_E + 1000],\n",
    "    range_y=[-r_E - 1000,r_E + 1000],\n",
    "\n",
    ")\n",
    "fig.update_traces(marker={'size': 1.5, 'color':'#6372f4'})\n",
    "# Add Earth\n",
    "earth=spheres(r_E, '#ffffff', 0) # Earth\n",
    "fig.add_trace(earth)\n",
    "#fig.add_trace(go.Scatter3d(x=xm, y=ym, z=zm, mode='lines', line=dict(color=zm, colorscale='Viridis')))\n",
    "fig['layout']['scene']['aspectmode'] = 'cube'\n",
    "fig.update_layout(transition = {'duration': 2000})\n",
    "fig.update_layout(paper_bgcolor='rgba(0,0,0,0)',\n",
    "            plot_bgcolor='rgba(0,0,0,0)')\n",
    "fig.write_html(\"plots/band.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Time to deorbit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:33.862766Z",
     "start_time": "2021-04-13T02:51:25.637468Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "AM = op.A / op.M\n",
    "z  = (da * (1 - de)) - op.cb['radius']\n",
    "z[z < 100*1e3] = 0\n",
    "\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='Altitude of 50 debris fragments over 3 years',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = 'Altitude [km]',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(25):\n",
    "    alt = np.trim_zeros(z[i, :]) / 1e3\n",
    "    scatter = go.Scatter(x=[i for i in range(len(alt))], y=alt,\n",
    "               mode='lines')\n",
    "    data.append(scatter)\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_layout(coloraxis=dict(colorscale='RdBu'), showlegend=False)\n",
    "fig.show()    \n",
    "fig.write_image(\"figures/oxp_altitudes.png\", width=500, height=500, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Debris spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:42.065755Z",
     "start_time": "2021-04-13T02:51:42.059087Z"
    }
   },
   "outputs": [],
   "source": [
    "index = int(np.ceil(ks_propagated.shape[0]*.10)) # index near begining\n",
    "raan_0 = ks_propagated[index, 3, :].copy() % 360\n",
    "raan_0[raan_0 > 180] -= 360 # Converting angles to new range\n",
    "\n",
    "raan_mid = ks_propagated[ks_propagated.shape[0] // 2, 3, :].copy()  % 360\n",
    "raan_mid[raan_mid  > 180] -= 360 \n",
    "\n",
    "raan_f = ks_propagated[-1, 3, :].copy() % 360\n",
    "raan_f[raan_f > 180] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:52:10.559324Z",
     "start_time": "2021-04-13T02:52:05.865763Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "uniform_dist = np.random.uniform(-180, 180, len(raan_0))\n",
    "group_labels = ['$\\Omega_{initial}$', '$\\Omega_{midpoint}$', '$\\Omega_{final}$', 'uniform']\n",
    "fig = ff.create_distplot([raan_0, raan_mid, raan_f, uniform_dist], group_labels, show_hist =  False)\n",
    "\n",
    "# Updating the uniform curve to be dashed\n",
    "index = np.argwhere(np.array([data.legendgroup for data in fig.data]) == 'uniform')[0][0]\n",
    "fig.data[index].line = dict(color='red', width=2,\n",
    "                             dash='dash')\n",
    "\n",
    "# Layout\n",
    "fig.layout['title'] = dict(text='Longitude of the ascending node distribution',\n",
    "                        x=0.5)\n",
    "fig.layout['xaxis_title'] = '$\\Omega\\:[deg]$'\n",
    "fig.layout['yaxis_title'] = 'Kernel density estimation'\n",
    "fig.layout['template'] = 'plotly_white'\n",
    "\n",
    "\n",
    "fig.write_image(\"figures/oxp_dist.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig, filename=\"Longitude of the ascending node distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1dd94164b79c718bb90761a659539b4f36f630021bae23010ca9f978c97e726"
  },
  "kernelspec": {
   "display_name": "Python [conda env:odap-env]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
