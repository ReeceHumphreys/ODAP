{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>0. Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:31:30.279038Z",
     "start_time": "2021-04-13T03:31:25.485517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3rd party lib.\n",
    "import numpy as np\n",
    "import re\n",
    "import skyfield.sgp4lib as spg4\n",
    "import matplotlib \n",
    "import PyQt5\n",
    "import chart_studio.plotly as py\n",
    "import chart_studio\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import os\n",
    "from skyfield.api import wgs84\n",
    "from enum import IntEnum    \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from itertools import product, combinations\n",
    "from matplotlib import cm\n",
    "from scipy import integrate\n",
    "from numba import njit, prange\n",
    "from skyfield.api import load, EarthSatellite, wgs84\n",
    "\n",
    "# User defined lib.\n",
    "import generate_debris as gd\n",
    "import CoordTransforms as ct\n",
    "import visualize_deb as vis\n",
    "import planetary_data\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib qt5\n",
    "debris_category = IntEnum('Category', 'rb sc soc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:31:38.437974Z",
     "start_time": "2021-04-13T03:31:38.422550Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Directory to Save Figures to\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.mkdir(\"figures\")\n",
    "\n",
    "# Create Directory to Save Interactive plots to\n",
    "if not os.path.exists(\"plots\"):\n",
    "    os.mkdir(\"plots\")\n",
    "    \n",
    "# Create Directory to Save gifs\n",
    "if not os.path.exists(\"gifs\"):\n",
    "    os.mkdir(\"gifs\")\n",
    "    \n",
    "# Retreiving API Keys from OS\n",
    "PLOTLY_API_KEY = os.environ.get('PLOTLY_API_KEY')\n",
    "PLOTYLY_USERNAME = 'rhumphreys2017'\n",
    "\n",
    "# Log into chart studio for uploading plots\n",
    "chart_studio.tools.set_credentials_file(username=PLOTYLY_USERNAME, api_key=PLOTLY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Data Source</h1>\n",
    "\n",
    "<h3>1.1 Loading TLE Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:31:41.682958Z",
     "start_time": "2021-04-13T03:31:40.796973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Opening the .txt file\n",
    "with open(\"3le.txt\") as f:\n",
    "    txt = f.read()\n",
    "    \n",
    "sat_lines = re.findall('(.*?)\\n(.*?)\\n(.*?)\\n', txt)\n",
    "\n",
    "# Convert each group of 3 lines into a satelite object\n",
    "def line_element_to_satellite(lines):\n",
    "    title = lines[0]\n",
    "    line1 = lines[1]\n",
    "    line2 = lines[2]\n",
    "    return spg4.EarthSatellite(line1, line2, name=title)\n",
    "\n",
    "satellites = [line_element_to_satellite(lines) for lines in sat_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Select orbital object for analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:32:06.383448Z",
     "start_time": "2021-04-13T03:32:06.342152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<EarthSatellite 0 OXP 1 catalog #22489 epoch 2019-12-19 08:49:27 UTC>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrive test satellite from TLE Data\n",
    "data = np.array(satellites)\n",
    "\n",
    "# Getting the satellite\n",
    "names = np.array([sat.name for sat in data])\n",
    "i_oxp1 = np.argwhere(names == \"0 OXP 1\").flatten()[0]\n",
    "satellite = data[i_oxp1]\n",
    "\n",
    "satellite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:13:24.736191Z",
     "start_time": "2021-04-13T02:13:24.731596Z"
    }
   },
   "source": [
    "# 2. Debris cloud simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Satellite breakup event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:14:08.714051Z",
     "start_time": "2021-04-13T02:14:08.708765Z"
    }
   },
   "source": [
    "#### 2.1.1 Exploring the NASA Breakup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:44:40.503265Z",
     "start_time": "2021-04-13T02:44:35.833034Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Explosion \n",
    "#\n",
    "\n",
    "m_target = 1000 # [kg]\n",
    "\n",
    "# Do not need to specify projectile mass, and collision velocity for an explosion\n",
    "# L_c [m], areas [m^2], masses [kg]\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, 0, 0, False, debris_category.rb, True)\n",
    "\n",
    "# LC DATA\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf] # L_c bins in meters\n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df = pd.DataFrame(ch)\n",
    "\n",
    "# MASS DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(masses*1e3, bins=bins) # grams\n",
    "ch = [ { f'>{bins[i]}g':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df2 = pd.DataFrame(ch)\n",
    "\n",
    "# AREA DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(areas*1e4, bins=bins) # cm^2\n",
    "ch = [ { f'>{bins[i]}cm^2':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df3 = pd.DataFrame(ch)\n",
    "\n",
    "# # VELOCITY DATA (A bit janky currently, always need to specify v_c event for explosions)\n",
    "deltaV = 10**np.array(gd.distribution_deltaV(AM, 5, True)) # Returns as [km·s^-1]\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(deltaV, bins=bins)\n",
    "ch = [ { f'>{bins[i]}km/s':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df4 = pd.DataFrame(ch)\n",
    "\n",
    "results = pd.concat([df, df2, df3, df4], axis=1)\n",
    "results\n",
    "m_target = 1000 # [kg]\n",
    "\n",
    "# Do not need to specify projectile mass, and collision velocity for an explosion\n",
    "# L_c [m], areas [m^2], masses [kg]\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, 0, 0, False, debris_category.rb, True)\n",
    "\n",
    "# LC DATA\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf] # L_c bins in meters\n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df = pd.DataFrame(ch)\n",
    "\n",
    "# MASS DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(masses*1e3, bins=bins) # grams\n",
    "ch = [ { f'>{bins[i]}g':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df2 = pd.DataFrame(ch)\n",
    "\n",
    "# AREA DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(areas*1e4, bins=bins) # cm^2\n",
    "ch = [ { f'>{bins[i]}cm^2':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df3 = pd.DataFrame(ch)\n",
    "\n",
    "# # VELOCITY DATA (A bit janky currently, always need to specify v_c event for explosions)\n",
    "deltaV = 10**np.array(gd.distribution_deltaV(AM, 5, True)) # Returns as [km·s^-1]\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(deltaV, bins=bins)\n",
    "ch = [ { f'>{bins[i]}km/s':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df4 = pd.DataFrame(ch)\n",
    "\n",
    "results = pd.concat([df, df2, df3, df4], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:44:49.401490Z",
     "start_time": "2021-04-13T02:44:45.246256Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Collision\n",
    "#\n",
    "\n",
    "m_target = 1000 # [kg]\n",
    "\n",
    "# Do not need to specify projectile mass, and collision velocity for an explosion\n",
    "# L_c [m], areas [m^2], masses [kg]\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, 10, 10, True, debris_category.rb, False)\n",
    "\n",
    "# LC DATA\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf] # L_c bins in meters\n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df = pd.DataFrame(ch)\n",
    "\n",
    "# MASS DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(masses*1e3, bins=bins) # grams\n",
    "ch = [ { f'>{bins[i]}g':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df2 = pd.DataFrame(ch)\n",
    "\n",
    "# AREA DATA\n",
    "bins = [1, np.inf]\n",
    "h,b = np.histogram(areas*1e4, bins=bins) # cm^2\n",
    "ch = [ { f'>{bins[i]}cm^2':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df3 = pd.DataFrame(ch)\n",
    "\n",
    "# # VELOCITY DATA (A bit janky currently, always need to specify v_c event for explosions)\n",
    "deltaV = 10**np.array(gd.distribution_deltaV(AM, 10, False)) # Returns as [km·s^-1]\n",
    "deltaV *= 1e3\n",
    "bins = [100, np.inf]\n",
    "h,b = np.histogram(deltaV, bins=bins)\n",
    "ch = [ { f'>{bins[i]}m/s':np.sum(h[i:]) for i in range(len(h))}]\n",
    "df4 = pd.DataFrame(ch)\n",
    "\n",
    "results = pd.concat([df, df2, df3, df4], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:22:17.012069Z",
     "start_time": "2021-04-13T02:22:16.999045Z"
    }
   },
   "source": [
    "#### 2.1.2 Visualizing the results of the NASA Breakup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "L_c, areas, masses, AM = gd.fragmentation(1000, 10, 10, True, debris_category.rb, False)\n",
    "N_fragments_total = L_c.shape[0]\n",
    "lambda_c = np.log10(L_c)\n",
    "\n",
    "# Logarithmic Spaced Bins\n",
    "def create_log_bins(values, nbins=100):\n",
    "    #return np.geomspace(values.min(), values.max(), nbins)\n",
    "    bins = np.geomspace(values.min(), values.max(), nbins)\n",
    "    a = bins[1]/bins[0]\n",
    "    bins = np.concatenate([[bins[0]/a], bins,[bins[-1]*a]])\n",
    "    return bins\n",
    "\n",
    "\n",
    "# Common Layout\n",
    "layout = dict(\n",
    "    autosize=False,\n",
    "    width=500,\n",
    "    height=500,\n",
    "    template = 'plotly_white',\n",
    "    yaxis = dict(\n",
    "        range=[0,8e5],\n",
    "        showexponent = 'all',\n",
    "        exponentformat = 'e'\n",
    "    ),\n",
    "    legend=dict(\n",
    "        y=0.5,\n",
    "        traceorder='reversed',\n",
    "        font=dict(\n",
    "            size=16\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "###### Validating L_c ######\n",
    "\n",
    "# Creating Histogram\n",
    "h, b = np.histogram(L_c, bins=create_log_bins(L_c)) # Test data\n",
    "# Make figure\n",
    "fig = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "\n",
    "# Update figure\n",
    "fig.update_xaxes(type=\"log\")\n",
    "fig.update_layout(\n",
    "    title = 'Characteristic Length Distribution',\n",
    "    xaxis_title=r'$\\log_{10}(L_{c}\\:[m])$',\n",
    "    yaxis_title=r'$N_f$'\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig.write_image(\"figures/N_f_vs_L_c.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig, filename=\"Characteristic Length Distribution\")\n",
    "\n",
    "# # # ###### Validating Areas ######\n",
    "\n",
    "# Creating Histogram\n",
    "h, b = np.histogram(areas, bins=create_log_bins(areas))\n",
    "\n",
    "# Make figure\n",
    "fig2 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "\n",
    "# Update figure\n",
    "fig2.update_xaxes(type=\"log\")\n",
    "fig2.update_layout(\n",
    "    title = 'Area distribution',\n",
    "    xaxis_title=r'$\\log_{10}(A\\:[m^2])$',\n",
    "    yaxis_title=r'$N_f$',\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig2.write_image(\"figures/N_f_vs_A.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig2, filename=\"Area distribution\")\n",
    "\n",
    "# ###### Validating MASS ######\n",
    "\n",
    "# # Creating Histogram\n",
    "h, b = np.histogram(masses, bins=create_log_bins(masses))\n",
    "\n",
    "# Make figure\n",
    "fig3 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "\n",
    "# Update figure\n",
    "fig3.update_xaxes(type=\"log\")\n",
    "fig3.update_layout(\n",
    "    title = 'Mass Distribution',\n",
    "    xaxis_title=r'$\\log_{10}(M\\:[kg])$',\n",
    "    yaxis_title=r'$N_f$'\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig3.write_image(\"figures/N_f_vs_M.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig3, filename=\"Mass Distribution\")\n",
    "\n",
    "### Validating Velocity\n",
    "deltaV = np.array(gd.distribution_deltaV(AM, 10, False))\n",
    "# Creating Histogram\n",
    "h, b = np.histogram(deltaV, bins=create_log_bins(deltaV))\n",
    "\n",
    "# Make figure\n",
    "fig4 = go.Figure(data=[go.Scatter(x=b, y=h, mode='lines', hoverinfo='all',\n",
    "                                 line=dict(shape='hvh'))],\n",
    "                layout=layout)\n",
    "\n",
    "# Update figure\n",
    "fig4.update_xaxes(type=\"log\")\n",
    "fig4.update_layout(\n",
    "    title = 'Velocity distribution',\n",
    "    xaxis_title=r'$\\log_{10}(V\\:[ms^-1])$',\n",
    "    yaxis_title=r'$N_f$',\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig4.write_image(\"figures/N_f_vs_V.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig4, filename=\"Velocity distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:04:58.954987Z",
     "start_time": "2021-04-13T02:04:58.934321Z"
    }
   },
   "source": [
    "#### 2.1.2 Perform fragmentation event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:18.050293Z",
     "start_time": "2021-04-13T03:32:28.591786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reecehumphreys/Developer/Thesis/Thesis/generate_debris.py:398: RuntimeWarning: invalid value encountered in power\n",
      "  found_L_c = np.sort((area / 0.556945)**(1/2.0047077)) # Inversing the Area function defined above\n"
     ]
    }
   ],
   "source": [
    "# Performing fragmentation event\n",
    "ts = load.timescale(builtin=True)\n",
    "t_fragmentation = ts.now()\n",
    "geocentric      = satellite.at(t_fragmentation)\n",
    "init_position   = geocentric.position.m\n",
    "\n",
    "m_target         = 250   # [kg] (Approx. mass of starlink sat)\n",
    "m_projectile     = 200     # [kg]\n",
    "v_impact         = 2   # [km·s^-1] (Measured relative to the target) (Needs to be in km·s^-1)\n",
    "is_catastrophic  = False\n",
    "is_explosion     = False\n",
    "\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, m_projectile, v_impact, is_catastrophic, debris_category.sc, is_explosion)\n",
    "deltaV = np.array(gd.distribution_deltaV(AM, v_impact, False)) # Returns as [km·s^-1]\n",
    "deltaV = deltaV * 1e3    #[m·s^-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:07:43.835833Z",
     "start_time": "2021-04-13T02:07:43.829932Z"
    }
   },
   "source": [
    "#### 2.1.3 Retriving Cartesian coordinates of debris fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:40.944054Z",
     "start_time": "2021-04-13T03:33:40.490279Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "init_position = geocentric.position.m\n",
    "deb_positions       = np.empty((len(AM), 3))\n",
    "deb_positions[:, :] = init_position[None,:]\n",
    "deb_velocities      = gd.velocity_vectors(len(AM), geocentric.velocity.m_per_s, deltaV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:09:37.908615Z",
     "start_time": "2021-04-13T02:09:37.901200Z"
    }
   },
   "source": [
    "#### 2.1.4 Converting coordinates to Keplerian elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:44.843674Z",
     "start_time": "2021-04-13T03:33:42.767256Z"
    }
   },
   "outputs": [],
   "source": [
    "keplerian_state     = ct.rv2coe(deb_positions, deb_velocities, planetary_data.earth['mu'])\n",
    "\n",
    "# Removing fragments that would renter earth\n",
    "periapsis           = keplerian_state[0, :] * (1 - keplerian_state[1, :])\n",
    "I                   = np.argwhere(periapsis > planetary_data.earth['radius'])\n",
    "keplerian_state     = np.squeeze(keplerian_state[:, I])\n",
    "areas               = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses              = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Ring Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:33:47.275860Z",
     "start_time": "2021-04-13T03:33:47.250686Z"
    }
   },
   "outputs": [],
   "source": [
    "## Shrink number of debris being used\n",
    "indexes = np.random.default_rng().choice(keplerian_state.shape[1], size=1000, replace=False)\n",
    "\n",
    "ks = keplerian_state[:, indexes]\n",
    "masses = masses[indexes]\n",
    "areas = areas[indexes]\n",
    "deb_positions = deb_positions[indexes, :]\n",
    "deb_velocities = deb_velocities[indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:30.754652Z",
     "start_time": "2021-04-13T03:33:50.015837Z"
    }
   },
   "outputs": [],
   "source": [
    "import Perturbations as OP\n",
    "import planetary_data as pd\n",
    "from Perturbations import null_perts\n",
    "\n",
    "# Cleanup states to remove any fragments that would deorbit, given no perturbations\n",
    "periapsis     = ks[0, :] * (1 - ks[1, :])\n",
    "I             = np.argwhere(periapsis > pd.earth['radius'])\n",
    "ks_pruned     = np.squeeze(ks[:, I])\n",
    "T             = ks_pruned[8, :]\n",
    "areas_pruned  = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses_pruned = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "\n",
    "# Propagate orbit for a period of time\n",
    "perts = null_perts()\n",
    "perts['aero'] = True\n",
    "perts['J2']   = True\n",
    "op = OP.OrbitPropagator(ks_pruned, areas_pruned, masses_pruned, [0, 1000*np.ceil(max(T))], 60*30, perts=perts)\n",
    "op.propagate_orbit()\n",
    "\n",
    "# Get the cartesian state representation\n",
    "cartesian_states = op.cartesian_representation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T01:17:23.880120Z",
     "start_time": "2021-04-09T01:17:23.841714Z"
    },
    "scrolled": true
   },
   "source": [
    "<h4>3.4.2 Particle Debris flux</h4>\n",
    "\n",
    "Using a particle flux to determine when the fragments of the debris have finished the formation of the ring. Indicating the end of the first phase of the debris cloud formation. This is accomplished by creating an xz plane and detecting when particles have switched from one side to the other. This approach will cause a peak as fragments pass through that becomes uniform as the debris becomes uniformly spread out.\n",
    "\n",
    "<h4>3.4.3 Convergence of the flux</h4>\n",
    "\n",
    "The next step is determining when the fragments have ended the torroid formation phase. This occurs when the fragments are approximately uniformally spread out. We can check to see when the flux meets a convergence criterion to determine when this happens.\n",
    "\n",
    "Now that the band has formed, we can shift away from propagating the exact position of each fragments and inplace propgate their changes in eccentricity and semi major axis due to drag. To do this first we must get the final states of the debris after the band has formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:34.645680Z",
     "start_time": "2021-04-13T03:34:34.433500Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "from dateutil import tz\n",
    "\n",
    "def fragmentation_flux(X):\n",
    "    return np.sum((X[:-1, :, 1] < 0) & (X[1:, :, 1] > 0), axis=1)\n",
    "    \n",
    "position = cartesian_states[:, 0, :, :]\n",
    "flux = fragmentation_flux(position)\n",
    "\n",
    "w = 100 # Window of points to look at\n",
    "tol = 5\n",
    "convergence_ratio = np.array([np.var(flux[i:i+w])/np.mean(flux[i:i+w]) for i in range(len(flux))])    \n",
    "intersection_index = np.argwhere(convergence_ratio <= tol).flatten()[0]\n",
    "\n",
    "# datetimes\n",
    "t_flux = t_fragmentation.utc_datetime() + np.array(range(len(flux))) * datetime.timedelta(minutes = 5)\n",
    "\n",
    "# Removing last window from `t_flux`, `flux`, and `convergence_ratio` bc. not well defined for last values\n",
    "t_flux = t_flux[:-w]\n",
    "flux = flux[:-w]\n",
    "convergence_ratio = convergence_ratio[:-w]\n",
    "\n",
    "# Pruning data to the end of the ring formation\n",
    "cs_toroid = cartesian_states[:intersection_index, :, :, :]\n",
    "ks_toroid = op.states[0:intersection_index, :, :]\n",
    "op.states = ks_toroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Band Formation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Drag Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:10:05.598741Z",
     "start_time": "2021-04-13T03:09:58.793458Z"
    }
   },
   "outputs": [],
   "source": [
    "import Aerodynamics as aero\n",
    "\n",
    "upper_bound = 900 * 1e3                         #[m]\n",
    "altitudes   = np.arange(0, upper_bound, 25)      #[m]\n",
    "rho         = aero.atmosphere_density(altitudes) #[kg·m^-3]\n",
    "\n",
    "I_standard = np.argwhere(altitudes/1e3 == 25).flatten()[0]\n",
    "I_cira    = np.argwhere(altitudes/1e3 == 500).flatten()[0]\n",
    "\n",
    "# Plotting the Exponential Atmospheric Model\n",
    "\n",
    "layout = go.Layout(\n",
    "    title        = go.layout.Title(text='Altitude (z) vs. Atmospheric Density (ρ)',\n",
    "                                   x=0.5),\n",
    "    xaxis_title  = 'z [km]',\n",
    "    yaxis_title  = '$\\log_{10}(\\\\rho\\:[kg·m^{-3}])$',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=altitudes[:I_standard] / 1e3, y=rho[:I_standard],\n",
    "                    mode='lines',\n",
    "                    name='U.S Standard Atmosphere'),\n",
    "    go.Scatter(x=altitudes[I_standard:I_cira] / 1e3, y=rho[I_standard:I_cira],\n",
    "                    mode='lines',\n",
    "                    name='CIRA-72'),\n",
    "    go.Scatter(x=altitudes[I_cira:] / 1e3, y=rho[I_cira:],\n",
    "                    mode='lines',\n",
    "                    name='CIRA-72 with T_infinity = 1000K')\n",
    "]\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_yaxes(type=\"log\")\n",
    "\n",
    "\n",
    "fig.write_image(\"figures/Atmospheric_Density_v_Altitude.png\", width=500, height=500, scale=2)\n",
    "f2 = go.FigureWidget(fig)\n",
    "f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Applying Perturbations to Satellite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:48:45.470540Z",
     "start_time": "2021-04-13T02:48:43.740049Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import iv\n",
    "from scipy import integrate\n",
    "import Aerodynamics as aero\n",
    "\n",
    "op.tspan[-1] = 3600*24*365*3\n",
    "op.dt = 3600*24\n",
    "de, da, di, dOmega, domega, dnu, dp = op.propagate_perturbations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Flux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 FLux plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:34:57.346240Z",
     "start_time": "2021-04-13T03:34:50.443218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2546\n"
     ]
    }
   ],
   "source": [
    "# Creating Flux v. Time plot\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='$\\\\text{Flux}\\:(\\\\Phi)\\:\\\\text{vs. Time }(t)$',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = '$\\\\text{ Number of fragments passing XZ plane, }\\Phi\\:$',\n",
    "    template     = 'plotly_white'\n",
    ")\n",
    "\n",
    "\n",
    "data = [\n",
    "    go.Scatter(x=t_flux, y=flux,\n",
    "               mode='lines',\n",
    "               name='Flux'),\n",
    "    go.Scatter(x=[t_flux[intersection_index], t_flux[intersection_index]], y=[0, np.max(flux)],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Convergence')\n",
    "]\n",
    "\n",
    "fig1 = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Stopping data to have half before intersection index and half after\n",
    "index_stop = intersection_index * 2\n",
    "if index_stop > len(flux) - 1 : index_stop = len(flux) - 1\n",
    "fig1.update_layout(xaxis_range=[t_flux[0],t_flux[index_stop]])\n",
    "\n",
    "# Saving plot as an image and uploading it to plotly\n",
    "fig1.write_image(\"figures/Flux_v_Time.png\", width=500, height=500, scale=2)\n",
    "#py.iplot(fig1, filename=\"Flux v. Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Convergence Ratio plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:35:40.893879Z",
     "start_time": "2021-04-13T03:35:40.588308Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating Convergence Ratio v. Time plot\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='Convergence ratio vs. Time (t)',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = 'Convergence ratio []',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "data = [\n",
    "    go.Scatter(x=t_flux, y=convergence_ratio,\n",
    "               mode='lines',\n",
    "               name='Convergence ratio'),\n",
    "    go.Scatter(x=[t_flux[intersection_index], t_flux[intersection_index]], y=[0, np.max(flux)],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Convergence time'),\n",
    "    go.Scatter(x=[t_flux[0], t_flux[-1]], y=[tol, tol],\n",
    "               mode='lines',\n",
    "               line=dict(dash = 'dash'),\n",
    "               name='Tolerance'),\n",
    "]\n",
    "fig2 = go.Figure(data=data, layout=layout)\n",
    "fig2.update_yaxes(type=\"log\")\n",
    "fig2.write_image(\"figures/Convergence_Ratio_v_Time.png\", width=500, height=500, scale=2)\n",
    "#py.iplot(fig2, filename=\"Convergence Ratio v. Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Ring visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T03:20:01.019781Z",
     "start_time": "2021-04-13T03:19:27.522113Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pandas\n",
    "\n",
    "spherical_earth_map = np.load('map_sphere.npy') \n",
    "\n",
    "pos_toroid = cs_toroid[:, 0, :, :]/1e3\n",
    "N_timesteps = pos_toroid.shape[0]\n",
    "N_fragments = pos_toroid.shape[1]\n",
    "r_E = op.cb['radius'] / 1e3\n",
    "xm, ym, zm = spherical_earth_map.T * r_E\n",
    "\n",
    "# Converting data to pandas dataframe\n",
    "df = pandas.DataFrame()\n",
    "# *** Update this if chnage timestep in initial orbit propagation ***\n",
    "dt = 60 * 5 #[s]\n",
    "# Want to show the evolution in 30 min\n",
    "timesteps = np.arange(0,N_timesteps, 6)\n",
    "\n",
    "for t in timesteps:   \n",
    "    step = t*np.ones_like(N_timesteps)\n",
    "    time = dt * step / 60 #[min]\n",
    "    d = {'X': pos_toroid[t, :, 0],\n",
    "         'Y': pos_toroid[t, :, 1],\n",
    "         'Z':pos_toroid[t, :, 2],\n",
    "         'Min.': time,\n",
    "         'a': ks_toroid[t, 0, :]/1e3,\n",
    "         'e': ks_toroid[t, 1, :],\n",
    "         'i': ks_toroid[t, 2, :],\n",
    "        }\n",
    "    df = pandas.concat([df, pandas.DataFrame(data=d)])\n",
    "\n",
    "# Creating visual\n",
    "def spheres(size, clr, dist=0): \n",
    "\n",
    "    # Set up 100 points. First, do angles\n",
    "    theta = np.linspace(0,2*np.pi,100)\n",
    "    phi = np.linspace(0,np.pi,100)\n",
    "\n",
    "    # Set up coordinates for points on the sphere\n",
    "    x0 = dist + size * np.outer(np.cos(theta),np.sin(phi))\n",
    "    y0 = size * np.outer(np.sin(theta),np.sin(phi))\n",
    "    z0 = size * np.outer(np.ones(100),np.cos(phi))\n",
    "\n",
    "    # Set up trace\n",
    "    trace= go.Surface(x=x0, y=y0, z=z0, colorscale=[[0,clr], [1,clr]])\n",
    "    trace.update(showscale=False)\n",
    "\n",
    "    return trace\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=df,\n",
    "    x='X',\n",
    "    y='Y',\n",
    "    z='Z',\n",
    "    title='Evolution of debris cloud to toroid formation',\n",
    "    hover_data={'Min.': False, 'X': False, 'Y':False, 'Z':False, 'a':':.1f', 'e':':.4f','i':':.1f' },\n",
    "    height=800,                 # height of graph in pixels\n",
    "    width =800,\n",
    "    animation_frame='Min.',   # assign marks to animation frames\n",
    "    range_x=[-r_E - 1000,r_E + 1000],\n",
    "    range_z=[-r_E - 1000,r_E + 1000],\n",
    "    range_y=[-r_E - 1000,r_E + 1000],\n",
    "\n",
    ")\n",
    "fig.update_traces(marker={'size': 3})\n",
    "# Add Earth\n",
    "earth=spheres(r_E, '#F0FFFF', 0) # Earth\n",
    "#fig.add_trace(go.Scatter3d(x=xm, y=ym, z=zm, mode='lines', line=dict(color=zm, colorscale='Viridis')))\n",
    "fig['layout']['scene']['aspectmode'] = 'cube'\n",
    "fig.add_trace(earth)\n",
    "fig.update_layout(transition = {'duration': 2000})\n",
    "fig.write_html(\"plots/ring.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Band visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:11.785292Z",
     "start_time": "2021-04-13T02:50:52.771515Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = np.zeros_like(da) # The params set to 0 dont matter for converting to rv\n",
    "ks_propagated = np.swapaxes(np.stack([da, de, di, dOmega, domega, temp, dnu, dp, temp, temp]).T, 1, 2)\n",
    "ks_final = np.concatenate([ks_toroid, ks_propagated])\n",
    "op.states = ks_final\n",
    "cs_final = op.cartesian_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:21.308114Z",
     "start_time": "2021-04-13T02:51:15.298065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "import plotly.express as px\n",
    "\n",
    "pos_toroid = cs_final[cs_toroid.shape[0]-1:, 0, :, :]/1e3\n",
    "N_timesteps = pos_toroid.shape[0]\n",
    "N_fragments = pos_toroid.shape[1]\n",
    "r_E = op.cb['radius'] / 1e3\n",
    "\n",
    "\n",
    "# Converting data to pandas dataframe\n",
    "df = pandas.DataFrame()\n",
    "# *** Update this if chnage timestep in initial orbit propagation ***\n",
    "dt = 60 * 5 #[s]\n",
    "# Want to show the evolution in 1 day steps\n",
    "timesteps = np.arange(0,N_timesteps, 5)\n",
    "\n",
    "for t in timesteps:   \n",
    "    step = t*np.ones_like(N_timesteps)\n",
    "    time = step  #[day]\n",
    "    d = {'X': pos_toroid[t, :, 0],\n",
    "         'Y': pos_toroid[t, :, 1],\n",
    "         'Z':pos_toroid[t, :, 2],\n",
    "         'Day': time,\n",
    "        }\n",
    "    df = pandas.concat([df, pandas.DataFrame(data=d)])\n",
    "\n",
    "def spheres(size, clr, dist=0): \n",
    "\n",
    "    # Set up 100 points. First, do angles\n",
    "    theta = np.linspace(0,2*np.pi,100)\n",
    "    phi = np.linspace(0,np.pi,100)\n",
    "\n",
    "    # Set up coordinates for points on the sphere\n",
    "    x0 = dist + size * np.outer(np.cos(theta),np.sin(phi))\n",
    "    y0 = size * np.outer(np.sin(theta),np.sin(phi))\n",
    "    z0 = size * np.outer(np.ones(100),np.cos(phi))\n",
    "\n",
    "    # Set up trace\n",
    "    trace= go.Surface(x=x0, y=y0, z=z0, colorscale=[[0,clr], [1,clr]])\n",
    "    trace.update(showscale=False)\n",
    "\n",
    "    return trace\n",
    "fig = px.scatter_3d(\n",
    "    data_frame=df,\n",
    "    x='X',\n",
    "    y='Y',\n",
    "    z='Z',\n",
    "    title='Evolution of debris cloud to Band formation',\n",
    "    #labels={'Years in school (avg)': 'Years Women are in School'},\n",
    "    #hover_data={'Min.': False, 'X': False, 'Y':False, 'Z':False, 'a':':.1f', 'e':':.4f','i':':.1f' },\n",
    "    #hover_name='Orbital Elements',        # values appear in bold in the hover tooltip\n",
    "    height=800,                 # height of graph in pixels\n",
    "    width =800,\n",
    "    animation_frame='Day',   # assign marks to animation frames\n",
    "    range_x=[-r_E - 1000,r_E + 1000],\n",
    "    range_z=[-r_E - 1000,r_E + 1000],\n",
    "    range_y=[-r_E - 1000,r_E + 1000],\n",
    "\n",
    ")\n",
    "fig.update_traces(marker={'size': 1.5, 'color':'#6372f4'})\n",
    "# Add Earth\n",
    "earth=spheres(r_E, '#ffffff', 0) # Earth\n",
    "fig.add_trace(earth)\n",
    "#fig.add_trace(go.Scatter3d(x=xm, y=ym, z=zm, mode='lines', line=dict(color=zm, colorscale='Viridis')))\n",
    "fig['layout']['scene']['aspectmode'] = 'cube'\n",
    "fig.update_layout(transition = {'duration': 2000})\n",
    "fig.update_layout(paper_bgcolor='rgba(0,0,0,0)',\n",
    "            plot_bgcolor='rgba(0,0,0,0)')\n",
    "fig.write_html(\"plots/band.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Time to deorbit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:33.862766Z",
     "start_time": "2021-04-13T02:51:25.637468Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "AM = op.A / op.M\n",
    "z  = (da * (1 - de)) - op.cb['radius']\n",
    "z[z < 100*1e3] = 0\n",
    "\n",
    "layout = go.Layout(\n",
    "    title        = dict(text='Altitude of 50 debris fragments over 3 years',\n",
    "                        x=0.5),\n",
    "    xaxis_title  = '$t\\:[days]$',\n",
    "    yaxis_title  = 'Altitude [km]',\n",
    "    template     = 'plotly_white',\n",
    "    legend       = go.layout.Legend(yanchor=\"top\",\n",
    "                             y=0.99,\n",
    "                             xanchor=\"right\",\n",
    "                             x=0.99)\n",
    ")\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(25):\n",
    "    alt = np.trim_zeros(z[i, :]) / 1e3\n",
    "    scatter = go.Scatter(x=[i for i in range(len(alt))], y=alt,\n",
    "               mode='lines')\n",
    "    data.append(scatter)\n",
    "    \n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_layout(coloraxis=dict(colorscale='RdBu'), showlegend=False)\n",
    "fig.show()    \n",
    "fig.write_image(\"figures/oxp_altitudes.png\", width=500, height=500, scale=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Debris spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:51:42.065755Z",
     "start_time": "2021-04-13T02:51:42.059087Z"
    }
   },
   "outputs": [],
   "source": [
    "index = int(np.ceil(ks_propagated.shape[0]*.10)) # index near begining\n",
    "raan_0 = ks_propagated[index, 3, :].copy() % 360\n",
    "raan_0[raan_0 > 180] -= 360 # Converting angles to new range\n",
    "\n",
    "raan_mid = ks_propagated[ks_propagated.shape[0] // 2, 3, :].copy()  % 360\n",
    "raan_mid[raan_mid  > 180] -= 360 \n",
    "\n",
    "raan_f = ks_propagated[-1, 3, :].copy() % 360\n",
    "raan_f[raan_f > 180] -= 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T02:52:10.559324Z",
     "start_time": "2021-04-13T02:52:05.865763Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "uniform_dist = np.random.uniform(-180, 180, len(raan_0))\n",
    "group_labels = ['$\\Omega_{initial}$', '$\\Omega_{midpoint}$', '$\\Omega_{final}$', 'uniform']\n",
    "fig = ff.create_distplot([raan_0, raan_mid, raan_f, uniform_dist], group_labels, show_hist =  False)\n",
    "\n",
    "# Updating the uniform curve to be dashed\n",
    "index = np.argwhere(np.array([data.legendgroup for data in fig.data]) == 'uniform')[0][0]\n",
    "fig.data[index].line = dict(color='red', width=2,\n",
    "                             dash='dash')\n",
    "\n",
    "# Layout\n",
    "fig.layout['title'] = dict(text='Longitude of the ascending node distribution',\n",
    "                        x=0.5)\n",
    "fig.layout['xaxis_title'] = '$\\Omega\\:[deg]$'\n",
    "fig.layout['yaxis_title'] = 'Kernel density estimation'\n",
    "fig.layout['template'] = 'plotly_white'\n",
    "\n",
    "\n",
    "fig.write_image(\"figures/oxp_dist.png\", width=500, height=500, scale=2)\n",
    "py.iplot(fig, filename=\"Longitude of the ascending node distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
