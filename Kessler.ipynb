{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>0. Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"glowscript\" class=\"glowscript\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "if (typeof Jupyter !== \"undefined\") { window.__context = { glowscript_container: $(\"#glowscript\").removeAttr(\"id\")};}else{ element.textContent = ' ';}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import numpy as np\n",
    "import re\n",
    "import skyfield.sgp4lib as spg4\n",
    "from   skyfield.api import wgs84\n",
    "import matplotlib \n",
    "import PyQt5\n",
    "\n",
    "# User defined lib.\n",
    "import generate_debris as gd\n",
    "import CoordTransforms as ct\n",
    "import visualize_deb as vis\n",
    "import planetary_data\n",
    "\n",
    "reload(gd)\n",
    "reload(ct)\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import norm\n",
    "import scipy.stats as stats\n",
    "from enum import IntEnum    \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import product, combinations\n",
    "from matplotlib import cm\n",
    "from scipy import integrate\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "\n",
    "%matplotlib qt5\n",
    "\n",
    "debris_category = IntEnum('Category', 'rb sc soc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1. Data Structure</h1>\n",
    "\n",
    "<h3>1.1 Satellite Structure</h3>\n",
    "\n",
    "Creating an object to represent satellite from 3le.txt <br>\n",
    "May end up using implementation from another package\n",
    "\n",
    "<b>Data sources:<b><br>\n",
    "https://www.space-track.org    \n",
    "https://www.celestrak.com/NORAD/documentation/spacetrk.pdf\n",
    "\n",
    "<b>Information about 3le/2le:</b><br>\n",
    "https://en.wikipedia.org/wiki/Two-line_element_set#cite_note-nasahelp-12\n",
    "https://spaceflight.nasa.gov/realdata/sightings/SSapplications/Post/JavaSSOP/SSOP_Help/tle_def.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class two_line_element:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.parse_data(data)\n",
    "        \n",
    "    def parse_data(self, satelite_data):\n",
    "        self.title = satelite_data[0]\n",
    "        line_one = satelite_data[1].split()\n",
    "        line_two = satelite_data[2].split()\n",
    "\n",
    "        self.catalog_number = re.search('[0-9]{1,5}', line_one[0]).group()\n",
    "        self.classification = re.search('[UCS]', line_one[0]).group()\n",
    "\n",
    "        international_designator = re.search('([0-9]{2})([0-9]{3})(\\w{1,3})', line_one[1])\n",
    "        self.launch_year = international_designator.group(1)\n",
    "        self.launch_number = international_designator.group(2)\n",
    "        self.launch_piece =  international_designator.group(3)\n",
    "\n",
    "        epoch = re.search('([0-9]{2})(\\d+\\.\\d+)', line_one[2])\n",
    "        self.epoch_year = epoch.group(1)\n",
    "        self.epoch_day = epoch.group(2)\n",
    "\n",
    "        self.ballistic_coefficient = float(line_one[3])\n",
    "        self.mean_motion_double_prime = line_one[4]\n",
    "        self.BSTAR = line_one[5]\n",
    "\n",
    "        self.inclination = line_two[1]\n",
    "        self.right_ascension_of_ascending_node = line_two[2]\n",
    "        self.eccentricity = line_two[3]\n",
    "        self.argument_of_perigee = line_two[4]\n",
    "\n",
    "        mean_anomaly = line_two[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Data structure implementation using spg4 from skyfield library<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0 VANGUARD 1', '1     5U 58002B   19352.86539842  .00000184  00000-0  20948-3 0  9994', '2     5  34.2610  67.7117 1845282 255.2293  83.7559 10.84789954185624')\n",
      "STARLINK-1026 TLE:\n",
      "0 STARLINK-31 catalog #44235 epoch 2019-12-19 06:00:01 UTC\n"
     ]
    }
   ],
   "source": [
    "# Opening the .txt file\n",
    "with open(\"3le.txt\") as f:\n",
    "    txt = f.read()\n",
    "    \n",
    "sat_lines = re.findall('(.*?)\\n(.*?)\\n(.*?)\\n', txt)\n",
    "\n",
    "# Preview of `sat_lines`, each element should be the three lines representing a satellite\n",
    "print(sat_lines[0])\n",
    "\n",
    "# Convert each group of 3 lines into a satelite object\n",
    "def line_element_to_satellite(lines):\n",
    "    title = lines[0]\n",
    "    line1 = lines[1]\n",
    "    line2 = lines[2]\n",
    "    return spg4.EarthSatellite(line1, line2, name=title)\n",
    "\n",
    "satellites = [line_element_to_satellite(lines) for lines in sat_lines]\n",
    "\n",
    "# Verify data structure by finding element representing the ISS\n",
    "starlink_index = [sat.name for sat in satellites].index(\"0 STARLINK-31\")\n",
    "starlink = satellites[starlink_index]\n",
    "print(\"STARLINK-1026 TLE:\")\n",
    "print(starlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1.2 Celestial Bodies</h3>\n",
    "\n",
    "\n",
    "de421.bsp is a Ephemerides provided by JPL Horizon which has the calculated positions of celestial bodies within a certain time interval. de421 is commonly used due to its small size and its relativley up to date information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import load, EarthSatellite\n",
    "ts = load.timescale(builtin=True)\n",
    "\n",
    "# Loading the data from de421.bsp using skyfield \n",
    "planets = load('de421.bsp')\n",
    "\n",
    "# Finding the data about Earth\n",
    "earth = planets[\"Earth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>2. Breakup Models</h1>\n",
    "\n",
    "<h3>2.1 NASA breakup model</h3>\n",
    "\n",
    "<b>Implementation:</b> (Found on page 207)<br>\n",
    "https://www.researchgate.net/publication/295490674_Space_debris_cloud_evolution_in_Low_Earth_Orbit\n",
    "\n",
    "<b>Alternate implementation:</b><br>\n",
    "https://gitlab.obspm.fr/apetit/nasa-breakup-model/tree/master\n",
    "\n",
    "<b>Information:</b><br>\n",
    "https://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?referer=https://en.wikipedia.org/&httpsredir=1&article=1094&context=theses\n",
    "\n",
    "\n",
    "<b>Now implemented in file generate_debris.py</b><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 NASA breakup model validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explosion Case\n",
    "\n",
    "reload(gd)\n",
    "\n",
    "m_target = 1000 # [kg]\n",
    "\n",
    "# Do not need to specify projectile mass, and collision velocity for an explosion\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, 0, 0, False, debris_category.rb, True)\n",
    "\n",
    "bins = [1e-3, 1e-2, 1e-1, 1, np.inf] # L_c bins in meters\n",
    "h,b = np.histogram(L_c, bins=bins)\n",
    "\n",
    "ch = [ { f'>{bins[i]}m':np.sum(h[i:]) for i in range(len(h))}]\n",
    "\n",
    "df = pd.DataFrame(ch)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(gd)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "L_c, areas, masses, AM = gd.fragmentation(1000, 10, 10, True, debris_category.rb, False)\n",
    "N_fragments_total = L_c.shape[0]\n",
    "lambda_c = np.log10(L_c)\n",
    "\n",
    "def create_log_bins(values, nbins=100):\n",
    "    #return np.geomspace(values.min(), values.max(), nbins)\n",
    "    bins = np.geomspace(values.min(), values.max(), nbins)\n",
    "    a = bins[1]/bins[0]\n",
    "    bins = np.concatenate([[bins[0]/a], bins,[bins[-1]*a]])\n",
    "    return bins\n",
    "\n",
    "# # # Validating L_c\n",
    "# h, b = np.histogram(L_c, bins=create_log_bins(L_c))\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r'$L_{c}$')\n",
    "# plt.ylabel(r'$N_f$')\n",
    "# plt.gca().set_xticks([1e-3, 1e-2, 1e-1, 1, 10])\n",
    "# plt.gca().set_xlim([1e-3,10])\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,5))\n",
    "# plt.gca().set_yticks([0, 2e5, 4e5, 6e5, 8e5])\n",
    "# plt.gca().set_ylim([0,8e5])\n",
    "# plt.plot((b[:-1] + b[1:])/2, h, '.-')\n",
    "# plt.show()\n",
    "\n",
    "# # # Validating Areas\n",
    "# h, b = np.histogram(areas, bins=create_log_bins(areas))\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r'$Areas$')\n",
    "# plt.ylabel(r'$N_f$')\n",
    "# plt.gca().set_xticks([1e-8,1e-6, 1e-4, 1e-2, 1, 1e2])\n",
    "# plt.gca().set_xlim([1e-8,1e2])\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,5))\n",
    "# plt.gca().set_yticks([0, 2e5, 4e5, 6e5, 8e5])\n",
    "# plt.gca().set_ylim([0,8e5])\n",
    "# plt.plot((b[:-1] + b[1:])/2, h, '.-')\n",
    "# plt.show()\n",
    "\n",
    "# # Validating Mass & Velocity\n",
    "# h, b = np.histogram(masses, bins=create_log_bins(masses))\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r'$Masses$')\n",
    "# plt.ylabel(r'$N_f$')\n",
    "# plt.gca().set_xticks([1e-8, 1e-5, 1e-2, 10, 1e4])\n",
    "# plt.gca().set_xlim([1e-8,1e4])\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,5))\n",
    "# plt.gca().set_yticks([0, 2e5, 4e5, 6e5, 8e5])\n",
    "# plt.gca().set_ylim([0,8e5])\n",
    "# plt.plot((b[:-1] + b[1:])/2, h, '.-')\n",
    "# plt.show()\n",
    "\n",
    "# # # Validating Velocity\n",
    "# deltaV = np.array(gd.distribution_deltaV(AM, 10, False))\n",
    "# h, b = np.histogram(deltaV, bins=create_log_bins(deltaV))\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.xscale('log')\n",
    "# plt.xlabel(r'$\\delta V$')\n",
    "# plt.ylabel(r'$N_f$')\n",
    "# plt.gca().set_xticks([1e-3, 1e-2, 1e-1, 1, 10])\n",
    "# plt.gca().set_xlim([1e-3,10])\n",
    "# plt.grid()\n",
    "# plt.plot((b[:-1] + b[1:])/2, h, '.-')\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0,5))\n",
    "# plt.gca().set_yticks([0, 2e5, 4e5, 6e5, 8e5])\n",
    "# plt.gca().set_ylim([0,8e5])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.3 and Onward will be alternate breakup models</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3. Numerical Propagation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.2 Calculating Orbital Debris Properties</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reecehumphreys/Developer/Thesis/Thesis/generate_debris.py:368: RuntimeWarning: invalid value encountered in power\n",
      "  found_L_c = np.sort((area / 0.556945)**(1/2.0047077)) # Inversing the Area function defined above\n"
     ]
    }
   ],
   "source": [
    "from skyfield.api import load, EarthSatellite\n",
    "reload(gd)\n",
    "\n",
    "ts = load.timescale(builtin=True)\n",
    "\n",
    "t_fragmentation = ts.now()\n",
    "geocentric      = starlink.at(t_fragmentation)\n",
    "init_position   = geocentric.position.m\n",
    "\n",
    "m_target         = 250   # [kg] (Approx. mass of starlink sat)\n",
    "m_projectile     = 200     # [kg]\n",
    "v_impact         = 2   # [km·s^-1] (Measured relative to the target) (Needs to be in km·s^-1)\n",
    "is_catastrophic  = False\n",
    "is_explosion     = False\n",
    "\n",
    "L_c, areas, masses, AM = gd.fragmentation(m_target, m_projectile, v_impact, is_catastrophic, debris_category.sc, is_explosion)\n",
    "deltaV = np.array(gd.distribution_deltaV(AM, v_impact, False)) # Returns as [km·s^-1]\n",
    "deltaV = deltaV * 1e3    #[m·s^-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.3 Converting Cartesian to Keplerian</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "init_position = geocentric.position.m\n",
    "\n",
    "reload(planetary_data)\n",
    "reload(ct)\n",
    "\n",
    "deb_positions       = np.empty((len(AM), 3))\n",
    "deb_positions[:, :] = init_position[None,:]\n",
    "deb_velocities      = gd.velocity_vectors(len(AM), geocentric.velocity.m_per_s, deltaV)\n",
    "\n",
    "keplerian_state     = ct.rv2coe(deb_positions, deb_velocities, planetary_data.earth['mu'])\n",
    "\n",
    "print(keplerian_state.shape)\n",
    "# Removing fragments that would renter earth\n",
    "periapsis           = keplerian_state[0, :] * (1 - keplerian_state[1, :])\n",
    "I                   = np.argwhere(periapsis > planetary_data.earth['radius'])\n",
    "keplerian_state     = np.squeeze(keplerian_state[:, I])\n",
    "areas  = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses              = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = 1\n",
    "\n",
    "print(\"Cartesian\")\n",
    "print(\"r: \", deb_positions[rand_index, :])\n",
    "print(\"v: \", deb_velocities[rand_index, :])\n",
    "print(\"m: \", masses[rand_index])\n",
    "print(\"m_E: \", planetary_data.earth['mass'])\n",
    "print(\"Keplerian\")\n",
    "ks_rand = keplerian_state[:, rand_index]\n",
    "print(\"a: \", ks_rand[0]) # a is tyically off in the thousands place\n",
    "print(\"e: \", ks_rand[1])\n",
    "print(\"i: \", ks_rand[2])\n",
    "print(\"Omega: \", ks_rand[3]) \n",
    "print(\"omega: \", ks_rand[4])\n",
    "print(\"M: \", ks_rand[5])\n",
    "print(\"nu: \", ks_rand[6])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4 Testing coverting back to Cartesian</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ct)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "indexes = np.random.default_rng().choice(keplerian_state.shape[1], size=1000, replace=False)\n",
    "ks_sample = keplerian_state[:, indexes]\n",
    "\n",
    "cartesian_state = np.array(ct.coe2rv_many(k=planetary_data.earth['mu'],\n",
    "                              p=ks_sample[7, :],\n",
    "                              ecc=ks_sample[1, :],\n",
    "                              inc=ks_sample[2, :],\n",
    "                              raan=ks_sample[3, :],\n",
    "                              argp=ks_sample[4, :],\n",
    "                              nu=ks_sample[6, :]))\n",
    "radius_earth = planetary_data.earth['radius']\n",
    "r = cartesian_state[0, :, :]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(r[:, 0], r[:, 1], r[:, 2])\n",
    "ax.set_xlim3d([-radius_earth-1000*1e3, radius_earth+1000*1e3])\n",
    "ax.set_xlabel('X (m)')\n",
    "\n",
    "ax.set_ylim3d([-radius_earth-1000*1e3, radius_earth+1000*1e3])\n",
    "ax.set_ylabel('Y (m)')\n",
    "\n",
    "ax.set_zlim3d([-radius_earth-1000*1e3, radius_earth+1000*1e3])\n",
    "ax.set_zlabel('Z (m)')\n",
    "\n",
    "_u, _v = np.mgrid[0:2*np.pi:20j, 0:np.pi:10j]\n",
    "_x = radius_earth*np.cos(_u)*np.sin(_v)\n",
    "_y = radius_earth*np.sin(_u)*np.sin(_v)\n",
    "_z = radius_earth*np.cos(_v)\n",
    "\n",
    "ax.plot_surface(_x, _y, _z, cmap=cm.coolwarm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keplerian_state.shape\n",
    "masses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3.4 Debris Cloud formation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Shrink number of debris being used\n",
    "indexes = np.random.default_rng().choice(keplerian_state.shape[1], size=250, replace=False)\n",
    "\n",
    "ks = keplerian_state[:, indexes]\n",
    "masses = masses[indexes]\n",
    "areas = areas[indexes]\n",
    "deb_positions = deb_positions[indexes, :]\n",
    "deb_velocities = deb_velocities[indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"debris.npz\",\n",
    "         keplerian_states=ks,\n",
    "         masses=masses,\n",
    "         areas=areas,\n",
    "         deb_positions=deb_positions,\n",
    "         deb_velocities=deb_velocities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = np.load('debris.npz')\n",
    "ks = container['keplerian_states']\n",
    "masses = container['masses']\n",
    "areas = container['areas']\n",
    "deb_positions = container['deb_positions']\n",
    "deb_velocities = container['deb_velocities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.4.1 Ellisoid formation</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Perturbations as OP\n",
    "import planetary_data as pd\n",
    "from Perturbations import null_perts\n",
    "\n",
    "reload(OP)\n",
    "\n",
    "# Cleanup states to remove any fragments that would deorbit, given no perturbations\n",
    "periapsis     = ks[0, :] * (1 - ks[1, :])\n",
    "I             = np.argwhere(periapsis > pd.earth['radius'])\n",
    "ks_pruned     = np.squeeze(ks[:, I])\n",
    "T             = ks_pruned[8, :]\n",
    "areas_pruned  = areas[I].flatten()  # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "masses_pruned = masses[I].flatten() # When doing the indexing , a 1d dim being added which is unneccesary\n",
    "\n",
    "# Propagate orbit for a period of time\n",
    "perts = null_perts()\n",
    "perts['aero'] = True\n",
    "perts['J2']   = True\n",
    "op = OP.OrbitPropagator(ks_pruned, areas_pruned, masses_pruned, [0, 20*np.ceil(max(T))], 60*5, perts=perts)\n",
    "op.propagate_orbit()\n",
    "\n",
    "# Get the cartesian state representation\n",
    "cartesian_states = op.cartesian_representation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.4.2 Particle Debris flux</h4>\n",
    "\n",
    "Using a particle flux to determine when the fragments of the debris have finished the formation of the ring. Indicating the end of the first phase of the debris cloud formation. This is accomplished by creating an xz plane and detecting when particles have switched from one side to the other. This approach will cause a peak as fragments pass through that becomes uniform as the debris becomes uniformly spread out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.dates as mdates\n",
    "from dateutil import tz\n",
    "\n",
    "def fragmentation_flux(X):\n",
    "    return np.sum((X[:-1, :, 1] < 0) & (X[1:, :, 1] > 0), axis=1)\n",
    "    \n",
    "position = cartesian_states[:, 0, :, :]\n",
    "flux = fragmentation_flux(position)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.4.3 Convergence of the flux</h4>\n",
    "\n",
    "The next step is determining when the fragments have ended the torroid formation phase. This occurs when the fragments are approximately uniformally spread out. We can check to see when the flux meets a convergence criterion to determine when this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 100 # Window of points to look at\n",
    "tol = 1.5\n",
    "convergence_ratio = np.array([np.var(flux[i:i+w])/np.mean(flux[i:i+w]) for i in range(len(flux))])    \n",
    "intersection_index = np.argwhere(convergence_ratio <= tol).flatten()[0] # Grabbing the first point that meets the criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# datetimes\n",
    "t_flux = t_fragmentation.utc_datetime() + np.array(range(len(flux))) * datetime.timedelta(minutes = 5)\n",
    "\n",
    "# Creating Flux v. Time plot\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# plt.plot(mdates.date2num(t_flux), flux, label='Flux')\n",
    "# plt.axvline(x=t_flux[intersection_index], color='r',ls=':', label='Intersection')\n",
    "# plt.xlim([t_flux[0], t_flux[-1]])\n",
    "# formatter = mdates.DateFormatter('%m/%d %H:%M UTC', tz=tz.UTC)\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "# plt.legend(frameon=False)\n",
    "# plt.xticks(rotation=60)\n",
    "# plt.xlabel(\"Date-Time\")\n",
    "# plt.ylabel(\"Flux\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "#Creating Convergence Ratio v. Time plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(mdates.date2num(t_flux), convergence_ratio, color='orange', label='Convergence ratio')\n",
    "plt.axhline(y=tol, color='k', ls=\":\", label='Threshold')\n",
    "plt.axvline(x=t_flux[intersection_index], color='r',ls=':', label='Intersection')\n",
    "formatter = mdates.DateFormatter('%m/%d %H:%M UTC', tz=tz.UTC)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "plt.legend(frameon=False)\n",
    "plt.xticks(rotation=60)\n",
    "plt.xlim([t_flux[0], t_flux[-1]])\n",
    "plt.yscale('symlog')\n",
    "plt.xlabel(\"Date-Time\")\n",
    "plt.ylabel(\"Convergence ratio\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>3.4.4 End of band formation</h4>\n",
    "\n",
    "Now that the band has formed, we can shift away from propagating the exact position of each fragments and inplace propgate their changes in eccentricity and semi major axis due to drag. To do this first we must get the final states of the debris after the band has formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vpython import *\n",
    "\n",
    "reload(vis)\n",
    "\n",
    "cs_toroid = cartesian_states[:intersection_index, :, :, :]\n",
    "ks_toroid = op.states[0:intersection_index, :, :]\n",
    "op.states = ks_toroid\n",
    "\n",
    "# Creating visual\n",
    "\n",
    "data = np.swapaxes(cs_toroid,0,1)[0, :, :, :]\n",
    "# canvas()\n",
    "# vis.visualize(data, op.cb)\n",
    "#vis.generate_visualization(data, \"Band_Formation\", op.cb)\n",
    "#op.states.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4.0.0 Implementing Perturbations </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing perturbations with the following effects:\n",
      "Aerodynamic perturbations ...\n",
      "J2 perturbations ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reecehumphreys/Developer/Thesis/Thesis/Perturbations.py:117: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  n = np.zeros_like(a)\n",
      "/Users/reecehumphreys/Developer/Thesis/Thesis/Perturbations.py:117: RuntimeWarning: invalid value encountered in multiply\n",
      "  n = np.zeros_like(a)\n"
     ]
    }
   ],
   "source": [
    "op.tspan[-1] = 60 * 60 * 24 * 365 / 2  #[s]\n",
    "op.dt = 60 * 60 * 1                   #[s]\n",
    "de, da, domega, dOmega = op.propagate_perturbations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "perigee = da * (1 - de)\n",
    "altitude = perigee - op.cb['radius']\n",
    "\n",
    "frag1 =  perigee[1, :]\n",
    "frag1 = np.trim_zeros(frag1)\n",
    "plt.plot(frag1 / 1e3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375  days to deorbit\n"
     ]
    }
   ],
   "source": [
    "print(len(frag1), ' days to deorbit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164.71523751 164.72020859 164.72517994 ... 167.49854959 167.49854959\n",
      " 167.49854959]\n"
     ]
    }
   ],
   "source": [
    "print(dOmega[0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
